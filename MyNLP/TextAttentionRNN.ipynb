{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from text_utils import *\n",
    "\n",
    "#current version\n",
    "#export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.0.1-cp36-cp36m-linux_x86_64.whl\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.rnn.python.ops import core_rnn_cell as rnn_cell\n",
    "from tensorflow.python.ops.rnn import bidirectional_dynamic_rnn,dynamic_rnn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "from os import walk\n",
    "import h5py\n",
    "import sys\n",
    "sys.path.append('../tfmodels')\n",
    "#from tf_object import *\n",
    "from sequential_model import *\n",
    "from collections import Counter\n",
    "\n",
    "data_path = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('{}/emotion_sents.dat'.format(data_path),'rb')\n",
    "new_sentences = pkl.load(f)\n",
    "label_str = pkl.load(f)\n",
    "f.close()\n",
    "df = pd.read_excel('{}/emotion.xlsx'.format(data_path))\n",
    "maxlen = 140\n",
    "phrase_dict = dict(zip(df.phrase, df.po1))\n",
    "id_term_map = pkl.load(open('{}/term_map.dat'.format(data_path),'rb'))\n",
    "term_dict = dict((v,k) for k,v in id_term_map.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = '{}/emotion_documents'.format(data_path)\n",
    "h5f = h5py.File(file_path + '.h5', 'r')\n",
    "documents = np.array(h5f['documents'])\n",
    "seq_len = np.array(h5f['seq_len'])\n",
    "label = np.array(h5f['label'])\n",
    "new_idx = np.array(h5f['new_idx'])\n",
    "nb_words = np.array(h5f['id_term_map_length'])\n",
    "h5f.close()\n",
    "label_str = [label_str[idx] for idx in new_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "\n",
    "flags.DEFINE_integer(\"nb_words\", nb_words, \"term number in input sequence(zero mask) [20001]\")\n",
    "flags.DEFINE_integer(\"maxlen\", maxlen, \"the max length of input sequence [80]\")\n",
    "flags.DEFINE_integer(\"num_layers\", 2, \"the number of rnn layers [1]\")\n",
    "flags.DEFINE_integer(\"init_std\", 0.05, \"init_std\")\n",
    "flags.DEFINE_integer(\"init_scale\", 1, \"init_scale\")\n",
    "flags.DEFINE_integer(\"embedding_size\", 300, \"word embedding size [50]\")\n",
    "flags.DEFINE_integer(\"hidden_size\", 512, \"rnn hidden size [128]\")\n",
    "flags.DEFINE_float(\"keep_prob\", 0.9, \"keep probability of drop out [0.9]\")\n",
    "flags.DEFINE_float(\"learning_rate\", 0.002, \"learning rate [0.001]\")\n",
    "flags.DEFINE_integer(\"batch_size\", 512, \"batch size to use during training [128]\")\n",
    "flags.DEFINE_float(\"clip_gradients\", 5.0, \"clip gradients to this norm [5.0]\")\n",
    "flags.DEFINE_integer(\"n_epochs\", 1, \"number of epoch to use during training [10]\")\n",
    "flags.DEFINE_boolean(\"epoch_save\", True, \"save checkpoint or not in each epoch [True]\")\n",
    "flags.DEFINE_integer(\"print_step\", 100, \"print step duraing training [100]\")\n",
    "flags.DEFINE_string(\"logs_dir\", \"logs/\", \"logs directory [logs/]\")\n",
    "flags.DEFINE_string(\"model_dir\", \"model/\", \"model directory [model/]\")\n",
    "flags.DEFINE_boolean(\"dir_clear\", False, \"clear the log and model directory\")\n",
    "flags.DEFINE_boolean(\"lr_annealing\", False, \"use lr annealing or not after each epoch [False]\")\n",
    "flags.DEFINE_string(\"current_task_name\", 'url_self_prediction', \"current task name [self_prediction]\")\n",
    "flags.DEFINE_integer(\"gpu_id\", 0, \"default gpu id [0]\")\n",
    "flags.DEFINE_integer(\"gpu_num\", 4, \"gpu_num\")\n",
    "\n",
    "FLAGS = flags.FLAGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionRNNModel(SequentialModel):\n",
    "    def __init__(self, config, sess, current_task_name='attention_rnn_model'):\n",
    "        super(AttentionRNNModel, self).__init__(config, sess, current_task_name)\n",
    "        \n",
    "    \n",
    "    def build_input_sequence(self, gpu_id=0, reuse=None):\n",
    "        #embedding layer\n",
    "        self.__build_embedding_layer__()\n",
    "        with get_new_variable_scope('rnn_lstm') as rnn_scope:\n",
    "            #fw_cell and bw_cell\n",
    "            cell_fw = rnn_cell.MultiRNNCell([rnn_cell.DropoutWrapper(rnn_cell.LSTMCell(self.hidden_size, use_peepholes=True, \n",
    "                                                                                       state_is_tuple=True,reuse=reuse),\n",
    "                                                             input_keep_prob=self.keep_prob, \n",
    "                                                             output_keep_prob=self.keep_prob) \n",
    "                                          for _ in range(self.num_layers)], state_is_tuple=True)\n",
    "            cell_bw = rnn_cell.MultiRNNCell([rnn_cell.DropoutWrapper(rnn_cell.LSTMCell(self.hidden_size, use_peepholes=True, \n",
    "                                                                                       state_is_tuple=True,reuse=reuse),\n",
    "                                                             input_keep_prob=self.keep_prob, \n",
    "                                                             output_keep_prob=self.keep_prob) \n",
    "                                          for _ in range(self.num_layers)], state_is_tuple=True)\n",
    "            self.state_list[gpu_id], self.output_list[gpu_id] = bidirectional_dynamic_rnn(cell_fw, cell_bw, self.input_embedding, \n",
    "                                                                self.split_seqLengths[gpu_id], dtype=tf.float32)  \n",
    "            self.state_list[gpu_id] = tf.concat(self.state_list[gpu_id],axis=2)\n",
    "\n",
    "    def build_single_prediction(self, type='self', gpu_id=0, accK=1, nb_class=2):\n",
    "        with tf.name_scope('pooling_over_time') as scope:\n",
    "            pool = tf.nn.max_pool(tf.expand_dims(self.state_list[gpu_id], -1),\n",
    "                                  ksize=[1, self.maxlen, 1, 1],\n",
    "                                  strides=[1, 1, 1, 1], padding='VALID', name=\"pool\")\n",
    "            pool_flat = tf.reshape(pool, [-1, self.hidden_size*2])\n",
    "        with get_new_variable_scope('prediction') as pred_scope:    \n",
    "            prediction = my_full_connected(pool_flat, nb_class, add_bias=True, act=tf.identity, init_std=self.init_std)\n",
    "            self.tower_prediction_results.append(tf.nn.softmax(prediction))\n",
    "        with tf.name_scope('loss'): \n",
    "            loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.split_label[gpu_id], \n",
    "                                                                  logits=prediction)\n",
    "            if self.params is None:\n",
    "                self.params = tf.trainable_variables()[1:]  \n",
    "            grads, capped_gvs = my_compute_grad(self.opt, loss, self.params, \n",
    "                                                clip_type = 'clip_norm', \n",
    "                                                max_clip_grad=self.clip_gradients)            \n",
    "        with tf.name_scope('accuracy'):\n",
    "            accuracy = tf.to_float(tf.nn.in_top_k(prediction, self.split_label[gpu_id],k=accK))        \n",
    "        self.__add_to_tower_list__(grads, capped_gvs, loss, accuracy, type)\n",
    "        \n",
    "    def build_model(self, type='self', accK=5, nb_c1ass=2):\n",
    "        self.build_input()\n",
    "        self.build_single_output()\n",
    "        for idx, gpu_id in enumerate(self.gpus):\n",
    "            with tf.device('/gpu:%d' % gpu_id):\n",
    "                with tf.name_scope('Tower_%d' % (gpu_id)) as tower_scope:\n",
    "                    reuse = (idx!=0)\n",
    "                    gpu_scope = tf.variable_scope('gpu', reuse=reuse)\n",
    "                    with gpu_scope as gpu_scope:\n",
    "                        self.build_input_sequence(gpu_id=idx, reuse=reuse)\n",
    "                        self.build_single_prediction(type=type,gpu_id=idx,accK=accK,nb_class=nb_c1ass)\n",
    "        self.build_model_aggregation()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idxs = np.arange(0, len(seq_len))\n",
    "label[label<=1] = 0\n",
    "label[label>=3] = 1\n",
    "#2387043\n",
    "idxs = np.append(np.random.choice(np.where(label == 0)[0], 2387043, replace=False),\n",
    "                 np.random.choice(np.where(label == 1)[0], 2387043, replace=False))\n",
    "#idxs = np.delete(idxs, np.where(seq_len==1)[0])\n",
    "#idxs = np.delete(idxs, np.where(label == 2)[0])\n",
    "#idxs = np.delete(idxs, np.where(label == 3)[0])\n",
    "#idxs = idxs[0:200000]\n",
    "train_idxs, test_idxs = train_test_split(idxs, test_size=0.2, random_state=42)\n",
    "test_idxs = np.sort(test_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_to_use = tf.Graph()\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth=True\n",
    "with tf.Session(graph=graph_to_use, config=config) as session:\n",
    "    #cnn_model = TextCNN(FLAGS, session, current_task_name='text_cnn_model')\n",
    "    #cnn_model.build_model(num_classes=len(set(label[idxs])),max_conv_len=7, num_filters=512, dropout_keep_prob=0.5)\n",
    "    attention_rnnlm_model = AttentionRNNModel(FLAGS, session, current_task_name='seq_model')\n",
    "    attention_rnnlm_model.build_model()\n",
    "    attention_rnnlm_model.build_model_summary()\n",
    "    display(attention_rnnlm_model.model_summary())\n",
    "    rnnlm_model.run([documents,label], train_idxs, test_idxs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
