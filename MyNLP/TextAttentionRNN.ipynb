{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from text_utils import *\n",
    "\n",
    "#current version\n",
    "#export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.0.1-cp36-cp36m-linux_x86_64.whl\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.rnn.python.ops import core_rnn_cell as rnn_cell\n",
    "from tensorflow.python.ops.rnn import bidirectional_dynamic_rnn,dynamic_rnn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "from os import walk\n",
    "import h5py\n",
    "import sys\n",
    "sys.path.append('../tfmodels')\n",
    "#from tf_object import *\n",
    "from sequential_model import *\n",
    "from collections import Counter\n",
    "\n",
    "data_path = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('{}/emotion_sents.dat'.format(data_path),'rb')\n",
    "new_sentences = pkl.load(f)\n",
    "label_str = pkl.load(f)\n",
    "f.close()\n",
    "df = pd.read_excel('{}/emotion.xlsx'.format(data_path))\n",
    "maxlen = 140\n",
    "phrase_dict = dict(zip(df.phrase, df.po1))\n",
    "id_term_map = pkl.load(open('{}/term_map.dat'.format(data_path),'rb'))\n",
    "term_dict = dict((v,k) for k,v in id_term_map.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = '{}/emotion_documents'.format(data_path)\n",
    "h5f = h5py.File(file_path + '.h5', 'r')\n",
    "documents = np.array(h5f['documents'])\n",
    "seq_len = np.array(h5f['seq_len'])\n",
    "label = np.array(h5f['label'])\n",
    "new_idx = np.array(h5f['new_idx'])\n",
    "nb_words = np.array(h5f['id_term_map_length'])\n",
    "h5f.close()\n",
    "label_str = [label_str[idx] for idx in new_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "\n",
    "flags.DEFINE_integer(\"nb_words\", nb_words, \"term number in input sequence(zero mask) [20001]\")\n",
    "flags.DEFINE_integer(\"maxlen\", maxlen, \"the max length of input sequence [80]\")\n",
    "flags.DEFINE_integer(\"num_layers\", 2, \"the number of rnn layers [1]\")\n",
    "flags.DEFINE_integer(\"init_std\", 0.05, \"init_std\")\n",
    "flags.DEFINE_integer(\"init_scale\", 1, \"init_scale\")\n",
    "flags.DEFINE_integer(\"embedding_size\", 300, \"word embedding size [50]\")\n",
    "flags.DEFINE_integer(\"hidden_size\", 512, \"rnn hidden size [128]\")\n",
    "flags.DEFINE_float(\"keep_prob\", 0.9, \"keep probability of drop out [0.9]\")\n",
    "flags.DEFINE_float(\"learning_rate\", 0.001, \"learning rate [0.001]\")\n",
    "flags.DEFINE_integer(\"batch_size\", 512, \"batch size to use during training [128]\")\n",
    "flags.DEFINE_float(\"clip_gradients\", 5.0, \"clip gradients to this norm [5.0]\")\n",
    "flags.DEFINE_integer(\"n_epochs\", 1, \"number of epoch to use during training [10]\")\n",
    "flags.DEFINE_boolean(\"epoch_save\", True, \"save checkpoint or not in each epoch [True]\")\n",
    "flags.DEFINE_integer(\"print_step\", 100, \"print step duraing training [100]\")\n",
    "flags.DEFINE_string(\"logs_dir\", \"logs/\", \"logs directory [logs/]\")\n",
    "flags.DEFINE_string(\"model_dir\", \"model/\", \"model directory [model/]\")\n",
    "flags.DEFINE_boolean(\"dir_clear\", False, \"clear the log and model directory\")\n",
    "flags.DEFINE_boolean(\"lr_annealing\", False, \"use lr annealing or not after each epoch [False]\")\n",
    "flags.DEFINE_string(\"current_task_name\", 'url_self_prediction', \"current task name [self_prediction]\")\n",
    "flags.DEFINE_integer(\"gpu_id\", 0, \"default gpu id [0]\")\n",
    "flags.DEFINE_integer(\"gpu_num\", 4, \"gpu_num\")\n",
    "\n",
    "FLAGS = flags.FLAGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionRNNModel(SequentialModel):\n",
    "    def __init__(self, config, sess, current_task_name='attention_rnn_model'):\n",
    "        super(AttentionRNNModel, self).__init__(config, sess, current_task_name)\n",
    "        \n",
    "    \n",
    "    def build_input_sequence(self, gpu_id=0, reuse=None):\n",
    "        #embedding layer\n",
    "        self.__build_embedding_layer__()\n",
    "        with get_new_variable_scope('rnn_lstm') as rnn_scope:\n",
    "            #fw_cell and bw_cell\n",
    "            cell_fw = rnn_cell.MultiRNNCell([rnn_cell.DropoutWrapper(rnn_cell.LSTMCell(self.hidden_size, use_peepholes=True, \n",
    "                                                                                       state_is_tuple=True,reuse=reuse),\n",
    "                                                             input_keep_prob=self.keep_prob, \n",
    "                                                             output_keep_prob=self.keep_prob) \n",
    "                                          for _ in range(self.num_layers)], state_is_tuple=True)\n",
    "            cell_bw = rnn_cell.MultiRNNCell([rnn_cell.DropoutWrapper(rnn_cell.LSTMCell(self.hidden_size, use_peepholes=True, \n",
    "                                                                                       state_is_tuple=True,reuse=reuse),\n",
    "                                                             input_keep_prob=self.keep_prob, \n",
    "                                                             output_keep_prob=self.keep_prob) \n",
    "                                          for _ in range(self.num_layers)], state_is_tuple=True)\n",
    "            self.state_list[gpu_id], self.output_list[gpu_id] = bidirectional_dynamic_rnn(cell_fw, cell_bw, self.input_embedding, \n",
    "                                                                self.split_seqLengths[gpu_id], dtype=tf.float32)  \n",
    "            self.state_list[gpu_id] = tf.concat(self.state_list[gpu_id],axis=2)\n",
    "\n",
    "    def build_single_prediction(self, type='self', gpu_id=0, accK=1, nb_class=2):\n",
    "        with tf.name_scope('pooling_over_time') as scope:\n",
    "            pool = tf.nn.max_pool(tf.expand_dims(self.state_list[gpu_id], -1),\n",
    "                                  ksize=[1, self.maxlen, 1, 1],\n",
    "                                  strides=[1, 1, 1, 1], padding='VALID', name=\"pool\")\n",
    "            pool_flat = tf.reshape(pool, [-1, self.hidden_size*2])\n",
    "        with get_new_variable_scope('prediction') as pred_scope:    \n",
    "            prediction = my_full_connected(pool_flat, nb_class, add_bias=True, act=tf.identity, init_std=self.init_std)\n",
    "            self.tower_prediction_results.append(tf.nn.softmax(prediction))\n",
    "        with tf.name_scope('loss'): \n",
    "            loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.split_label[gpu_id], \n",
    "                                                                  logits=prediction)\n",
    "            if self.params is None:\n",
    "                self.params = tf.trainable_variables()[1:]  \n",
    "            grads, capped_gvs = my_compute_grad(self.opt, loss, self.params, \n",
    "                                                clip_type = 'clip_norm', \n",
    "                                                max_clip_grad=self.clip_gradients)            \n",
    "        with tf.name_scope('accuracy'):\n",
    "            accuracy = tf.to_float(tf.nn.in_top_k(prediction, self.split_label[gpu_id],k=accK))        \n",
    "        self.__add_to_tower_list__(grads, capped_gvs, loss, accuracy, type)\n",
    "        \n",
    "    def build_model(self, type='self', accK=5, nb_c1ass=2):\n",
    "        self.build_input()\n",
    "        self.build_single_output()\n",
    "        for idx, gpu_id in enumerate(self.gpus):\n",
    "            with tf.device('/gpu:%d' % gpu_id):\n",
    "                with tf.name_scope('Tower_%d' % (gpu_id)) as tower_scope:\n",
    "                    reuse = (idx!=0)\n",
    "                    gpu_scope = tf.variable_scope('gpu', reuse=reuse)\n",
    "                    with gpu_scope as gpu_scope:\n",
    "                        self.build_input_sequence(gpu_id=idx, reuse=reuse)\n",
    "                        self.build_single_prediction(type=type,gpu_id=idx,accK=accK,nb_class=nb_c1ass)\n",
    "        self.build_model_aggregation()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idxs = np.arange(0, len(seq_len))\n",
    "label[label<=1] = 0\n",
    "label[label>=3] = 1\n",
    "#2387043\n",
    "idxs = np.append(np.random.choice(np.where(label == 0)[0], 2387043, replace=False),\n",
    "                 np.random.choice(np.where(label == 1)[0], 2387043, replace=False))\n",
    "#idxs = np.delete(idxs, np.where(seq_len==1)[0])\n",
    "#idxs = np.delete(idxs, np.where(label == 2)[0])\n",
    "#idxs = np.delete(idxs, np.where(label == 3)[0])\n",
    "#idxs = idxs[0:200000]\n",
    "train_idxs, test_idxs = train_test_split(idxs, test_size=0.2, random_state=42)\n",
    "test_idxs = np.sort(test_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>variable_shape</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>global/Variable:0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpu/embedding/embedding_layer/embedding_table:0</td>\n",
       "      <td>[15987, 300]</td>\n",
       "      <td>4796100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpu/rnn_lstm/bidirectional_rnn/fw/multi_rnn_ce...</td>\n",
       "      <td>[812, 2048]</td>\n",
       "      <td>1662976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpu/rnn_lstm/bidirectional_rnn/fw/multi_rnn_ce...</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpu/rnn_lstm/bidirectional_rnn/fw/multi_rnn_ce...</td>\n",
       "      <td>[512]</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpu/rnn_lstm/bidirectional_rnn/fw/multi_rnn_ce...</td>\n",
       "      <td>[512]</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpu/rnn_lstm/bidirectional_rnn/fw/multi_rnn_ce...</td>\n",
       "      <td>[512]</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpu/rnn_lstm/bidirectional_rnn/fw/multi_rnn_ce...</td>\n",
       "      <td>[1024, 2048]</td>\n",
       "      <td>2097152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpu/rnn_lstm/bidirectional_rnn/fw/multi_rnn_ce...</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpu/rnn_lstm/bidirectional_rnn/fw/multi_rnn_ce...</td>\n",
       "      <td>[512]</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpu/rnn_lstm/bidirectional_rnn/fw/multi_rnn_ce...</td>\n",
       "      <td>[512]</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpu/rnn_lstm/bidirectional_rnn/fw/multi_rnn_ce...</td>\n",
       "      <td>[512]</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpu/rnn_lstm/bidirectional_rnn/bw/multi_rnn_ce...</td>\n",
       "      <td>[812, 2048]</td>\n",
       "      <td>1662976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gpu/rnn_lstm/bidirectional_rnn/bw/multi_rnn_ce...</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gpu/rnn_lstm/bidirectional_rnn/bw/multi_rnn_ce...</td>\n",
       "      <td>[512]</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gpu/rnn_lstm/bidirectional_rnn/bw/multi_rnn_ce...</td>\n",
       "      <td>[512]</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gpu/rnn_lstm/bidirectional_rnn/bw/multi_rnn_ce...</td>\n",
       "      <td>[512]</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gpu/rnn_lstm/bidirectional_rnn/bw/multi_rnn_ce...</td>\n",
       "      <td>[1024, 2048]</td>\n",
       "      <td>2097152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gpu/rnn_lstm/bidirectional_rnn/bw/multi_rnn_ce...</td>\n",
       "      <td>[2048]</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gpu/rnn_lstm/bidirectional_rnn/bw/multi_rnn_ce...</td>\n",
       "      <td>[512]</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gpu/rnn_lstm/bidirectional_rnn/bw/multi_rnn_ce...</td>\n",
       "      <td>[512]</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gpu/rnn_lstm/bidirectional_rnn/bw/multi_rnn_ce...</td>\n",
       "      <td>[512]</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gpu/prediction/fully_connected/W:0</td>\n",
       "      <td>[1024, 2]</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gpu/prediction/fully_connected/B:0</td>\n",
       "      <td>[2]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        variable_name variable_shape  \\\n",
       "0                                   global/Variable:0             []   \n",
       "1     gpu/embedding/embedding_layer/embedding_table:0   [15987, 300]   \n",
       "2   gpu/rnn_lstm/bidirectional_rnn/fw/multi_rnn_ce...    [812, 2048]   \n",
       "3   gpu/rnn_lstm/bidirectional_rnn/fw/multi_rnn_ce...         [2048]   \n",
       "4   gpu/rnn_lstm/bidirectional_rnn/fw/multi_rnn_ce...          [512]   \n",
       "5   gpu/rnn_lstm/bidirectional_rnn/fw/multi_rnn_ce...          [512]   \n",
       "6   gpu/rnn_lstm/bidirectional_rnn/fw/multi_rnn_ce...          [512]   \n",
       "7   gpu/rnn_lstm/bidirectional_rnn/fw/multi_rnn_ce...   [1024, 2048]   \n",
       "8   gpu/rnn_lstm/bidirectional_rnn/fw/multi_rnn_ce...         [2048]   \n",
       "9   gpu/rnn_lstm/bidirectional_rnn/fw/multi_rnn_ce...          [512]   \n",
       "10  gpu/rnn_lstm/bidirectional_rnn/fw/multi_rnn_ce...          [512]   \n",
       "11  gpu/rnn_lstm/bidirectional_rnn/fw/multi_rnn_ce...          [512]   \n",
       "12  gpu/rnn_lstm/bidirectional_rnn/bw/multi_rnn_ce...    [812, 2048]   \n",
       "13  gpu/rnn_lstm/bidirectional_rnn/bw/multi_rnn_ce...         [2048]   \n",
       "14  gpu/rnn_lstm/bidirectional_rnn/bw/multi_rnn_ce...          [512]   \n",
       "15  gpu/rnn_lstm/bidirectional_rnn/bw/multi_rnn_ce...          [512]   \n",
       "16  gpu/rnn_lstm/bidirectional_rnn/bw/multi_rnn_ce...          [512]   \n",
       "17  gpu/rnn_lstm/bidirectional_rnn/bw/multi_rnn_ce...   [1024, 2048]   \n",
       "18  gpu/rnn_lstm/bidirectional_rnn/bw/multi_rnn_ce...         [2048]   \n",
       "19  gpu/rnn_lstm/bidirectional_rnn/bw/multi_rnn_ce...          [512]   \n",
       "20  gpu/rnn_lstm/bidirectional_rnn/bw/multi_rnn_ce...          [512]   \n",
       "21  gpu/rnn_lstm/bidirectional_rnn/bw/multi_rnn_ce...          [512]   \n",
       "22                 gpu/prediction/fully_connected/W:0      [1024, 2]   \n",
       "23                 gpu/prediction/fully_connected/B:0            [2]   \n",
       "\n",
       "   parameters  \n",
       "0           1  \n",
       "1     4796100  \n",
       "2     1662976  \n",
       "3        2048  \n",
       "4         512  \n",
       "5         512  \n",
       "6         512  \n",
       "7     2097152  \n",
       "8        2048  \n",
       "9         512  \n",
       "10        512  \n",
       "11        512  \n",
       "12    1662976  \n",
       "13       2048  \n",
       "14        512  \n",
       "15        512  \n",
       "16        512  \n",
       "17    2097152  \n",
       "18       2048  \n",
       "19        512  \n",
       "20        512  \n",
       "21        512  \n",
       "22       2048  \n",
       "23          2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 ... training ...\n"
     ]
    }
   ],
   "source": [
    "graph_to_use = tf.Graph()\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth=True\n",
    "with tf.Session(graph=graph_to_use, config=config) as session:\n",
    "    #cnn_model = TextCNN(FLAGS, session, current_task_name='text_cnn_model')\n",
    "    #cnn_model.build_model(num_classes=len(set(label[idxs])),max_conv_len=7, num_filters=512, dropout_keep_prob=0.5)\n",
    "    attention_rnnlm_model = AttentionRNNModel(FLAGS, session, current_task_name='attention_rnnlm_model')\n",
    "    attention_rnnlm_model.build_model()\n",
    "    attention_rnnlm_model.build_model_summary()\n",
    "    display(attention_rnnlm_model.model_summary())\n",
    "    attention_rnnlm_model.run([documents,seq_len,label], train_idxs, test_idxs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
