{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "sys.path.append('../tftools/')\n",
    "\n",
    "from tf_object import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UserRankModel(TFModel):\n",
    "    def __init__(self, config, sess, current_task_name='user_rank'):\n",
    "        super(UserRankModel, self).__init__(config, sess)\n",
    "        #self.net_size = config.net_size\n",
    "        self.feature_num = config.feature_num\n",
    "        self.event_num = config.event_num\n",
    "        self.current_task_name = current_task_name\n",
    "        self.init_scale = config.init_scale\n",
    "        \n",
    "    def build_input(self):\n",
    "        with tf.name_scope('input'):\n",
    "            inputX = tf.placeholder(tf.float32, [None, self.feature_num], name=\"input_feature\")\n",
    "            eventID = tf.placeholder(tf.int32, [None,2], name='event')\n",
    "            inputLabel = tf.placeholder(tf.int32, [None], name='label')\n",
    "            tf.add_to_collection(tf.GraphKeys.INPUTS, inputX)\n",
    "            tf.add_to_collection(tf.GraphKeys.INPUTS, eventID)\n",
    "            tf.add_to_collection(tf.GraphKeys.INPUTS, inputLabel)\n",
    "            self.split_inputX = tf.split(inputX, self.gpu_num, 0)\n",
    "            self.split_eventID = tf.split(eventID, self.gpu_num, 0)\n",
    "            self.split_inputLabel = tf.split(inputLabel, self.gpu_num, 0)\n",
    "        self.__build_global_setting__()\n",
    "        with tf.name_scope('states_array'):\n",
    "            self.last_flat = [[] for i in range(0,self.gpu_num)]\n",
    "     \n",
    "    def build_mlp_model(self, gpu_id=0, layer_num=4,net_size=512):\n",
    "        with get_new_variable_scope('embedding') as embedding_scope:\n",
    "            event_embedding = my_embedding_layer(self.split_eventID[gpu_id], self.event_num, net_size, \n",
    "                                  layer_name='embedding_layer', init_scale=self.init_scale)\n",
    "        dense = self.split_inputX[gpu_id]\n",
    "        with get_new_variable_scope('mlp') as mlp_scope:\n",
    "            for i in range(0, layer_num):            \n",
    "                dense = my_full_connected(highway(dense), net_size, act=tf.nn.tanh)\n",
    "        with tf.name_scope(\"dropout\"):\n",
    "            self.last_flat[gpu_id] = tf.reshape(tf.matmul(event_embedding, tf.reshape(dense, [-1,1,net_size]), adjoint_b=True), [-1,2])\n",
    "            \n",
    "    def build_prediction(self, gpu_id=0, accK=1):\n",
    "        prediction = self.last_flat[gpu_id]\n",
    "        self.tower_prediction_results.append(tf.nn.softmax(prediction))\n",
    "        self.params = tf.trainable_variables()[1:]\n",
    "        with tf.name_scope('loss'): \n",
    "            loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.split_inputLabel[gpu_id], logits=prediction)\n",
    "            grads, capped_gvs = my_compute_grad(self.opt, loss, self.params, \n",
    "                                                clip_type = 'clip_norm', \n",
    "                                                max_clip_grad=self.clip_gradients)           \n",
    "        with tf.name_scope('accuracy'):\n",
    "            #accuracy = tf.to_float(tf.equal(tf.cast(prediction>0.5,tf.int32), tf.cast(self.split_inputLabel[gpu_id],tf.int32)))\n",
    "            accuracy = tf.to_float(tf.nn.in_top_k(prediction, self.split_inputLabel[gpu_id],k=accK))\n",
    "        self.__add_to_tower_list__(grads,capped_gvs,loss,accuracy)\n",
    "              \n",
    "    def build_model(self,*args, **kwargs):\n",
    "        self.build_input()\n",
    "        for idx, gpu_id in enumerate(self.gpus):\n",
    "            with tf.device('/gpu:%d' % gpu_id):\n",
    "                with tf.name_scope('Tower_%d' % (gpu_id)) as tower_scope:\n",
    "                    gpu_scope = tf.variable_scope('gpu', reuse=(idx!=0))\n",
    "                    with gpu_scope as gpu_scope:\n",
    "                        self.build_mlp_model(gpu_id=idx, *args, **kwargs)\n",
    "                        self.build_prediction(gpu_id=idx)                       \n",
    "        self.build_model_aggregation()          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "\n",
    "flags.DEFINE_integer(\"feature_num\", 52, \"term number in input sequence(zero mask) [20001]\")\n",
    "flags.DEFINE_integer(\"event_num\", 26, \"the max length of input sequence [80]\")\n",
    "flags.DEFINE_float(\"init_scale\", 1.0, \"init scale for embedding layer\")\n",
    "flags.DEFINE_float(\"learning_rate\", 0.01, \"learning rate [0.001]\")\n",
    "flags.DEFINE_string(\"opt\", 'sgd', \"optimizer\")\n",
    "flags.DEFINE_integer(\"batch_size\", 512, \"batch size to use during training [128]\")\n",
    "flags.DEFINE_float(\"clip_gradients\", 5.0, \"clip gradients to this norm [5.0]\")\n",
    "flags.DEFINE_integer(\"n_epochs\", 100, \"number of epoch to use during training [10]\")\n",
    "flags.DEFINE_boolean(\"epoch_save\", True, \"save checkpoint or not in each epoch [True]\")\n",
    "flags.DEFINE_integer(\"print_step\", 1000, \"print step duraing training [100]\")\n",
    "flags.DEFINE_string(\"logs_dir\", \"logs/\", \"logs directory [logs/]\")\n",
    "flags.DEFINE_string(\"model_dir\", \"model/\", \"model directory [model/]\")\n",
    "flags.DEFINE_boolean(\"dir_clear\", False, \"clear the log and model directory\")\n",
    "flags.DEFINE_boolean(\"lr_annealing\", True, \"use lr annealing or not after each epoch [False]\")\n",
    "flags.DEFINE_integer(\"gpu_id\", 0, \"default gpu id [0]\")\n",
    "flags.DEFINE_integer(\"gpu_num\", 4, \"gpu_num\")\n",
    "\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('train_data.npy')\n",
    "event = np.concatenate([np.random.randint(25, size=[len(data),1]),data[:,-1:]],1)\n",
    "data = data[event[:,0]!=event[:,1]]\n",
    "event = event[event[:,0]!=event[:,1]]\n",
    "label = data[:,-2]\n",
    "#balance data\n",
    "r_idx = np.random.choice(np.where(label==0)[0], int((np.sum(label==0) - np.sum(label==1))/2), replace=False)\n",
    "event[r_idx, 0], event[r_idx, 1] = event[r_idx, 1], event[r_idx, 0].copy()\n",
    "label[r_idx] = 1\n",
    "data = data[:,:-2]\n",
    "data = scale(data, axis=0, with_mean=True, with_std=True, copy=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idxs = np.append(np.random.choice(np.where(label==1)[0],300000), np.random.choice(np.where(label==0)[0],300000))\n",
    "idxs = np.arange(0, len(data))\n",
    "train_idxs, test_idxs = train_test_split(idxs, test_size=0.2, random_state=42)\n",
    "test_idxs = np.sort(test_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>variable_shape</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>global/Variable:0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpu/embedding/embedding_layer/embedding_table:0</td>\n",
       "      <td>[26, 512]</td>\n",
       "      <td>13312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpu/mlp/highway/output_lin_0/Matrix:0</td>\n",
       "      <td>[52, 52]</td>\n",
       "      <td>2704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpu/mlp/highway/transform_lin_0/Matrix:0</td>\n",
       "      <td>[52, 52]</td>\n",
       "      <td>2704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpu/mlp/fully_connected/W:0</td>\n",
       "      <td>[52, 512]</td>\n",
       "      <td>26624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpu/mlp/fully_connected/B:0</td>\n",
       "      <td>[512]</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpu/mlp/highway_1/output_lin_0/Matrix:0</td>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>262144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpu/mlp/highway_1/transform_lin_0/Matrix:0</td>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>262144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpu/mlp/fully_connected_1/W:0</td>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>262144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpu/mlp/fully_connected_1/B:0</td>\n",
       "      <td>[512]</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpu/mlp/highway_2/output_lin_0/Matrix:0</td>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>262144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpu/mlp/highway_2/transform_lin_0/Matrix:0</td>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>262144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpu/mlp/fully_connected_2/W:0</td>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>262144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gpu/mlp/fully_connected_2/B:0</td>\n",
       "      <td>[512]</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gpu/mlp/highway_3/output_lin_0/Matrix:0</td>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>262144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gpu/mlp/highway_3/transform_lin_0/Matrix:0</td>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>262144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gpu/mlp/fully_connected_3/W:0</td>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>262144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gpu/mlp/fully_connected_3/B:0</td>\n",
       "      <td>[512]</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      variable_name variable_shape parameters\n",
       "0                                 global/Variable:0             []          1\n",
       "1   gpu/embedding/embedding_layer/embedding_table:0      [26, 512]      13312\n",
       "2             gpu/mlp/highway/output_lin_0/Matrix:0       [52, 52]       2704\n",
       "3          gpu/mlp/highway/transform_lin_0/Matrix:0       [52, 52]       2704\n",
       "4                       gpu/mlp/fully_connected/W:0      [52, 512]      26624\n",
       "5                       gpu/mlp/fully_connected/B:0          [512]        512\n",
       "6           gpu/mlp/highway_1/output_lin_0/Matrix:0     [512, 512]     262144\n",
       "7        gpu/mlp/highway_1/transform_lin_0/Matrix:0     [512, 512]     262144\n",
       "8                     gpu/mlp/fully_connected_1/W:0     [512, 512]     262144\n",
       "9                     gpu/mlp/fully_connected_1/B:0          [512]        512\n",
       "10          gpu/mlp/highway_2/output_lin_0/Matrix:0     [512, 512]     262144\n",
       "11       gpu/mlp/highway_2/transform_lin_0/Matrix:0     [512, 512]     262144\n",
       "12                    gpu/mlp/fully_connected_2/W:0     [512, 512]     262144\n",
       "13                    gpu/mlp/fully_connected_2/B:0          [512]        512\n",
       "14          gpu/mlp/highway_3/output_lin_0/Matrix:0     [512, 512]     262144\n",
       "15       gpu/mlp/highway_3/transform_lin_0/Matrix:0     [512, 512]     262144\n",
       "16                    gpu/mlp/fully_connected_3/W:0     [512, 512]     262144\n",
       "17                    gpu/mlp/fully_connected_3/B:0          [512]        512"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 ... training ...\n",
      "Minibatch 1000 / loss: 0.349792\n",
      "Minibatch 1000 / accuracy: 0.875\n",
      "Minibatch 2000 / loss: 0.330902\n",
      "Minibatch 2000 / accuracy: 0.878906\n",
      "Minibatch 3000 / loss: 0.367553\n",
      "Minibatch 3000 / accuracy: 0.880859\n",
      "Minibatch 4000 / loss: 0.361562\n",
      "Minibatch 4000 / accuracy: 0.873047\n",
      "Minibatch 5000 / loss: 0.318727\n",
      "Minibatch 5000 / accuracy: 0.894531\n",
      "Minibatch 6000 / loss: 0.363195\n",
      "Minibatch 6000 / accuracy: 0.861328\n",
      "epoch time: 1.8296393235524495\n",
      "Epoch 1 training accuracy: 0.867941721046\n",
      "Epoch 1 ... test ...\n",
      "Minibatch 1000 / loss: 0.304258\n",
      "Minibatch 1000 / accuracy: 0.90625\n",
      "Epoch 1 test accuracy: 0.874689313291\n",
      "Model saved in file: model/user_rank_model.ckpt\n",
      "{'loss': 0.37317928242710563, 'valid_los': 0.36241576049709873, 'best_accuracy': 0.86794172104642142, 'best_test_accuracy': 0.87468931329099464, 'epoch': 0, 'learning_rate': 0.01, 'valid_perplexity': 1.4367961808919685}\n",
      "Epoch 2 ... training ...\n",
      "Minibatch 1000 / loss: 0.361452\n",
      "Minibatch 1000 / accuracy: 0.867188\n",
      "Minibatch 2000 / loss: 0.333247\n",
      "Minibatch 2000 / accuracy: 0.880859\n",
      "Minibatch 3000 / loss: 0.344803\n",
      "Minibatch 3000 / accuracy: 0.890625\n",
      "Minibatch 4000 / loss: 0.364936\n",
      "Minibatch 4000 / accuracy: 0.869141\n",
      "Minibatch 5000 / loss: 0.351313\n",
      "Minibatch 5000 / accuracy: 0.871094\n",
      "Minibatch 6000 / loss: 0.340987\n",
      "Minibatch 6000 / accuracy: 0.882812\n",
      "epoch time: 1.7825883030891418\n",
      "Epoch 2 training accuracy: 0.877262904079\n",
      "Epoch 2 ... test ...\n",
      "Minibatch 1000 / loss: 0.295776\n",
      "Minibatch 1000 / accuracy: 0.914062\n",
      "Epoch 2 test accuracy: 0.876595696075\n",
      "Model saved in file: model/user_rank_model.ckpt\n",
      "{'loss': 0.35597470070669884, 'valid_los': 0.3572263215607438, 'best_accuracy': 0.8772629040787957, 'best_test_accuracy': 0.87659569607529586, 'epoch': 1, 'learning_rate': 0.01, 'valid_perplexity': 1.4293593280837062}\n",
      "Epoch 3 ... training ...\n",
      "Minibatch 1000 / loss: 0.380703\n",
      "Minibatch 1000 / accuracy: 0.867188\n",
      "Minibatch 2000 / loss: 0.325468\n",
      "Minibatch 2000 / accuracy: 0.900391\n",
      "Minibatch 3000 / loss: 0.379434\n",
      "Minibatch 3000 / accuracy: 0.863281\n",
      "Minibatch 4000 / loss: 0.306278\n",
      "Minibatch 4000 / accuracy: 0.904297\n",
      "Minibatch 5000 / loss: 0.344699\n",
      "Minibatch 5000 / accuracy: 0.878906\n",
      "Minibatch 6000 / loss: 0.362245\n",
      "Minibatch 6000 / accuracy: 0.865234\n",
      "epoch time: 1.7856807390848795\n",
      "Epoch 3 training accuracy: 0.878991671988\n",
      "Epoch 3 ... test ...\n",
      "Minibatch 1000 / loss: 0.296756\n",
      "Minibatch 1000 / accuracy: 0.914062\n",
      "Epoch 3 test accuracy: 0.878679124595\n",
      "Model saved in file: model/user_rank_model.ckpt\n",
      "{'loss': 0.35192470350516686, 'valid_los': 0.35204966132864257, 'best_accuracy': 0.87899167198756334, 'best_test_accuracy': 0.87867912459450814, 'epoch': 2, 'learning_rate': 0.01, 'valid_perplexity': 1.4219791393384917}\n",
      "Epoch 4 ... training ...\n",
      "Minibatch 1000 / loss: 0.345713\n",
      "Minibatch 1000 / accuracy: 0.876953\n",
      "Minibatch 2000 / loss: 0.374947\n",
      "Minibatch 2000 / accuracy: 0.867188\n",
      "Minibatch 3000 / loss: 0.36033\n",
      "Minibatch 3000 / accuracy: 0.873047\n",
      "Minibatch 4000 / loss: 0.353025\n",
      "Minibatch 4000 / accuracy: 0.861328\n",
      "Minibatch 5000 / loss: 0.341908\n",
      "Minibatch 5000 / accuracy: 0.896484\n",
      "Minibatch 6000 / loss: 0.352545\n",
      "Minibatch 6000 / accuracy: 0.888672\n",
      "epoch time: 1.7870575229326884\n",
      "Epoch 4 training accuracy: 0.880061943233\n",
      "Epoch 4 ... test ...\n",
      "Minibatch 1000 / loss: 0.30981\n",
      "Minibatch 1000 / accuracy: 0.910156\n",
      "Epoch 4 test accuracy: 0.879364462923\n",
      "Model saved in file: model/user_rank_model.ckpt\n",
      "{'loss': 0.34948143387791142, 'valid_los': 0.35157806289121396, 'best_accuracy': 0.8800619432333614, 'best_test_accuracy': 0.87936446292319637, 'epoch': 3, 'learning_rate': 0.01, 'valid_perplexity': 1.4213086943011655}\n",
      "Epoch 5 ... training ...\n",
      "Minibatch 1000 / loss: 0.371319\n",
      "Minibatch 1000 / accuracy: 0.878906\n",
      "Minibatch 2000 / loss: 0.395969\n",
      "Minibatch 2000 / accuracy: 0.857422\n",
      "Minibatch 3000 / loss: 0.417686\n",
      "Minibatch 3000 / accuracy: 0.847656\n",
      "Minibatch 4000 / loss: 0.323618\n",
      "Minibatch 4000 / accuracy: 0.894531\n",
      "Minibatch 5000 / loss: 0.323855\n",
      "Minibatch 5000 / accuracy: 0.890625\n",
      "Minibatch 6000 / loss: 0.333231\n",
      "Minibatch 6000 / accuracy: 0.886719\n",
      "epoch time: 1.7881795088450114\n",
      "Epoch 5 training accuracy: 0.881447756028\n",
      "Epoch 5 ... test ...\n",
      "Minibatch 1000 / loss: 0.290792\n",
      "Minibatch 1000 / accuracy: 0.914062\n",
      "Epoch 5 test accuracy: 0.880920180929\n",
      "Model saved in file: model/user_rank_model.ckpt\n",
      "{'loss': 0.34683673880241561, 'valid_los': 0.3478084879152008, 'best_accuracy': 0.88144775602841419, 'best_test_accuracy': 0.88092018092931879, 'epoch': 4, 'learning_rate': 0.01, 'valid_perplexity': 1.4159610501191473}\n",
      "Epoch 6 ... training ...\n",
      "Minibatch 1000 / loss: 0.30785\n",
      "Minibatch 1000 / accuracy: 0.894531\n",
      "Minibatch 2000 / loss: 0.302241\n",
      "Minibatch 2000 / accuracy: 0.910156\n",
      "Minibatch 3000 / loss: 0.369143\n",
      "Minibatch 3000 / accuracy: 0.859375\n",
      "Minibatch 4000 / loss: 0.343439\n",
      "Minibatch 4000 / accuracy: 0.867188\n",
      "Minibatch 5000 / loss: 0.350614\n",
      "Minibatch 5000 / accuracy: 0.888672\n",
      "Minibatch 6000 / loss: 0.340857\n",
      "Minibatch 6000 / accuracy: 0.884766\n",
      "epoch time: 1.787478260199229\n",
      "Epoch 6 training accuracy: 0.882440926624\n",
      "Epoch 6 ... test ...\n",
      "Minibatch 1000 / loss: 0.287779\n",
      "Minibatch 1000 / accuracy: 0.914062\n",
      "Epoch 6 test accuracy: 0.883709507927\n",
      "Model saved in file: model/user_rank_model.ckpt\n",
      "{'loss': 0.34453471328267155, 'valid_los': 0.34425922065609721, 'best_accuracy': 0.88244092662416806, 'best_test_accuracy': 0.88370950792708003, 'epoch': 5, 'learning_rate': 0.01, 'valid_perplexity': 1.4109443340233083}\n",
      "Epoch 7 ... training ...\n",
      "Minibatch 1000 / loss: 0.360426\n",
      "Minibatch 1000 / accuracy: 0.890625\n",
      "Minibatch 2000 / loss: 0.301621\n",
      "Minibatch 2000 / accuracy: 0.900391\n",
      "Minibatch 3000 / loss: 0.318368\n",
      "Minibatch 3000 / accuracy: 0.894531\n",
      "Minibatch 4000 / loss: 0.349562\n",
      "Minibatch 4000 / accuracy: 0.884766\n",
      "Minibatch 5000 / loss: 0.325053\n",
      "Minibatch 5000 / accuracy: 0.888672\n",
      "Minibatch 6000 / loss: 0.392291\n",
      "Minibatch 6000 / accuracy: 0.863281\n",
      "epoch time: 1.784655503431956\n",
      "Epoch 7 training accuracy: 0.88307372307\n",
      "Epoch 7 ... test ...\n",
      "Minibatch 1000 / loss: 0.291418\n",
      "Minibatch 1000 / accuracy: 0.914062\n",
      "Epoch 7 test accuracy: 0.883306300544\n",
      "{'loss': 0.34293009169837313, 'valid_los': 0.34332637524557957, 'best_accuracy': 0.88307372307045628, 'best_test_accuracy': 0.88370950792708003, 'epoch': 6, 'learning_rate': 0.01, 'valid_perplexity': 1.409628754788246}\n",
      "Epoch 8 ... training ...\n",
      "Minibatch 1000 / loss: 0.331992\n",
      "Minibatch 1000 / accuracy: 0.894531\n",
      "Minibatch 2000 / loss: 0.338361\n",
      "Minibatch 2000 / accuracy: 0.884766\n",
      "Minibatch 3000 / loss: 0.354986\n",
      "Minibatch 3000 / accuracy: 0.880859\n",
      "Minibatch 4000 / loss: 0.323812\n",
      "Minibatch 4000 / accuracy: 0.886719\n",
      "Minibatch 5000 / loss: 0.381907\n",
      "Minibatch 5000 / accuracy: 0.865234\n",
      "Minibatch 6000 / loss: 0.31252\n",
      "Minibatch 6000 / accuracy: 0.898438\n",
      "epoch time: 1.7891451597213746\n",
      "Epoch 8 training accuracy: 0.883558600492\n",
      "Epoch 8 ... test ...\n",
      "Minibatch 1000 / loss: 0.282041\n",
      "Minibatch 1000 / accuracy: 0.912109\n",
      "Epoch 8 test accuracy: 0.882087540549\n",
      "{'loss': 0.34155902083316675, 'valid_los': 0.34489640682825423, 'best_accuracy': 0.88355860049184498, 'best_test_accuracy': 0.88370950792708003, 'epoch': 7, 'learning_rate': 0.01, 'valid_perplexity': 1.411843654729563}\n",
      "Epoch 9 ... training ...\n",
      "Minibatch 1000 / loss: 0.374449\n",
      "Minibatch 1000 / accuracy: 0.859375\n",
      "Minibatch 2000 / loss: 0.371905\n",
      "Minibatch 2000 / accuracy: 0.876953\n",
      "Minibatch 3000 / loss: 0.330654\n",
      "Minibatch 3000 / accuracy: 0.886719\n"
     ]
    }
   ],
   "source": [
    "graph_to_use = tf.Graph()\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth=True\n",
    "with tf.Session(graph=graph_to_use, config=config) as session:\n",
    "    #cnn_model = TextCNN(FLAGS, session, current_task_name='text_cnn_model')\n",
    "    #cnn_model.build_model(num_classes=len(set(label[idxs])),max_conv_len=7, num_filters=512, dropout_keep_prob=0.5)\n",
    "    user_rank_model = UserRankModel(FLAGS, session, current_task_name='user_rank_model')\n",
    "    #label[idxs]\n",
    "    user_rank_model.build_model(net_size=512)\n",
    "    user_rank_model.build_model_summary()\n",
    "    display(user_rank_model.model_summary())\n",
    "    user_rank_model.run([data,event,label], train_idxs, test_idxs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
