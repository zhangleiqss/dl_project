{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import pickle as pkl\n",
    "sys.path.append('../tftools/')\n",
    "\n",
    "from tf_object import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UserRankModel(TFModel):\n",
    "    def __init__(self, config, sess, current_task_name='user_rank'):\n",
    "        super(UserRankModel, self).__init__(config, sess)\n",
    "        #self.net_size = config.net_size\n",
    "        self.feature_num = config.feature_num\n",
    "        self.event_num = config.event_num\n",
    "        self.current_task_name = current_task_name\n",
    "        self.init_scale = config.init_scale\n",
    "        \n",
    "    def build_input(self):\n",
    "        with tf.name_scope('input'):\n",
    "            inputX = tf.placeholder(tf.float32, [None, self.feature_num], name=\"input_feature\")\n",
    "            eventID = tf.placeholder(tf.int32, [None,2], name='event')\n",
    "            inputLabel = tf.placeholder(tf.int32, [None], name='label')\n",
    "            tf.add_to_collection(tf.GraphKeys.INPUTS, inputX)\n",
    "            tf.add_to_collection(tf.GraphKeys.INPUTS, eventID)\n",
    "            tf.add_to_collection(tf.GraphKeys.INPUTS, inputLabel)\n",
    "            self.split_inputX = tf.split(inputX, self.gpu_num, 0)\n",
    "            self.split_eventID = tf.split(eventID, self.gpu_num, 0)\n",
    "            self.split_inputLabel = tf.split(inputLabel, self.gpu_num, 0)\n",
    "        self.__build_global_setting__()\n",
    "        with tf.name_scope('states_array'):\n",
    "            self.last_flat = [[] for i in range(0,self.gpu_num)]\n",
    "     \n",
    "    def build_mlp_model(self, gpu_id=0, layer_num=2, net_size=512):\n",
    "        with get_new_variable_scope('embedding') as embedding_scope:\n",
    "            event_embedding = my_embedding_layer(self.split_eventID[gpu_id], self.event_num, net_size, \n",
    "                                  layer_name='embedding_layer', init_scale=self.init_scale)\n",
    "        dense = self.split_inputX[gpu_id]\n",
    "        with get_new_variable_scope('mlp') as mlp_scope:\n",
    "            dense = my_full_connected(dense, net_size, act=tf.nn.relu)\n",
    "            for i in range(0, layer_num):            \n",
    "                dense = highway(dense, f=tf.nn.tanh)\n",
    "            #for i in range(0, layer_num):            \n",
    "                #dense = highway(dense, f=tf.nn.relu)\n",
    "        with tf.name_scope(\"dropout\"):\n",
    "            self.last_flat[gpu_id] = tf.reshape(tf.matmul(event_embedding, tf.reshape(dense, [-1,1,net_size]), adjoint_b=True), [-1,2])\n",
    "            \n",
    "    def build_prediction(self, gpu_id=0, accK=1):\n",
    "        prediction = self.last_flat[gpu_id]\n",
    "        self.tower_prediction_results.append(tf.nn.softmax(prediction))\n",
    "        self.params = tf.trainable_variables()[1:]\n",
    "        with tf.name_scope('loss'): \n",
    "            loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.split_inputLabel[gpu_id], logits=prediction)\n",
    "            grads, capped_gvs = my_compute_grad(self.opt, loss, self.params, \n",
    "                                                clip_type = 'clip_norm', \n",
    "                                                max_clip_grad=self.clip_gradients)           \n",
    "        with tf.name_scope('accuracy'):\n",
    "            #accuracy = tf.to_float(tf.equal(tf.cast(prediction>0.5,tf.int32), tf.cast(self.split_inputLabel[gpu_id],tf.int32)))\n",
    "            accuracy = tf.to_float(tf.nn.in_top_k(prediction, self.split_inputLabel[gpu_id],k=accK))\n",
    "        self.__add_to_tower_list__(grads,capped_gvs,loss,accuracy)\n",
    "              \n",
    "    def build_model(self,*args, **kwargs):\n",
    "        self.build_input()\n",
    "        for idx, gpu_id in enumerate(self.gpus):\n",
    "            with tf.device('/gpu:%d' % gpu_id):\n",
    "                with tf.name_scope('Tower_%d' % (gpu_id)) as tower_scope:\n",
    "                    gpu_scope = tf.variable_scope('gpu', reuse=(idx!=0))\n",
    "                    with gpu_scope as gpu_scope:\n",
    "                        self.build_mlp_model(gpu_id=idx, *args, **kwargs)\n",
    "                        self.build_prediction(gpu_id=idx)                       \n",
    "        self.build_model_aggregation()          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "\n",
    "flags.DEFINE_integer(\"feature_num\", 51, \"term number in input sequence(zero mask) [20001]\")\n",
    "flags.DEFINE_integer(\"event_num\", 26, \"the max length of input sequence [80]\")\n",
    "flags.DEFINE_float(\"init_scale\", 1.0, \"init scale for embedding layer\")\n",
    "flags.DEFINE_float(\"learning_rate\", 0.01, \"learning rate [0.001]\")\n",
    "flags.DEFINE_string(\"opt\", 'sgd', \"optimizer\")\n",
    "flags.DEFINE_integer(\"batch_size\", 512, \"batch size to use during training [128]\")\n",
    "flags.DEFINE_float(\"clip_gradients\", 5.0, \"clip gradients to this norm [5.0]\")\n",
    "flags.DEFINE_integer(\"n_epochs\", 100, \"number of epoch to use during training [10]\")\n",
    "flags.DEFINE_boolean(\"epoch_save\", True, \"save checkpoint or not in each epoch [True]\")\n",
    "flags.DEFINE_integer(\"print_step\", 500, \"print step duraing training [100]\")\n",
    "flags.DEFINE_string(\"logs_dir\", \"logs/\", \"logs directory [logs/]\")\n",
    "flags.DEFINE_string(\"model_dir\", \"model/\", \"model directory [model/]\")\n",
    "flags.DEFINE_boolean(\"dir_clear\", False, \"clear the log and model directory\")\n",
    "flags.DEFINE_boolean(\"lr_annealing\", True, \"use lr annealing or not after each epoch [False]\")\n",
    "flags.DEFINE_integer(\"gpu_id\", 0, \"default gpu id [0]\")\n",
    "flags.DEFINE_integer(\"gpu_num\", 4, \"gpu_num\")\n",
    "\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load('train_data.npy')\n",
    "#fliter bad case\n",
    "data = np.delete(data, 8, 1)\n",
    "data = data[data[:,8]>50]\n",
    "#get the data\n",
    "event = np.concatenate([np.random.randint(25, size=[len(data),1]),data[:,-1:]],1)\n",
    "label = data[:,-2]\n",
    "data = data[:,:-2]\n",
    "data = scale(data, axis=0, with_mean=True, with_std=True, copy=True)\n",
    "#select data \n",
    "data = data[event[:,0]!=event[:,1]]\n",
    "label = label[event[:,0]!=event[:,1]]\n",
    "event = event[event[:,0]!=event[:,1]]\n",
    "#balance data\n",
    "r_idx = np.random.choice(np.where(label==0)[0], int((np.sum(label==0) - np.sum(label==1))/2), replace=False)\n",
    "event[r_idx, 0], event[r_idx, 1] = event[r_idx, 1], event[r_idx, 0].copy()\n",
    "label[r_idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#idxs = np.append(np.random.choice(np.where(label==1)[0],300000), np.random.choice(np.where(label==0)[0],300000))\n",
    "idxs = np.arange(0, len(data))\n",
    "train_idxs, test_idxs = train_test_split(idxs, test_size=0.2)\n",
    "test_idxs = np.sort(test_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>variable_shape</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>global/Variable:0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpu/embedding/embedding_layer/embedding_table:0</td>\n",
       "      <td>[26, 512]</td>\n",
       "      <td>13312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpu/mlp/fully_connected/W:0</td>\n",
       "      <td>[51, 512]</td>\n",
       "      <td>26112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpu/mlp/fully_connected/B:0</td>\n",
       "      <td>[512]</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpu/mlp/highway/output_lin_0/Matrix:0</td>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>262144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpu/mlp/highway/transform_lin_0/Matrix:0</td>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>262144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpu/mlp/highway_1/output_lin_0/Matrix:0</td>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>262144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpu/mlp/highway_1/transform_lin_0/Matrix:0</td>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>262144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     variable_name variable_shape parameters\n",
       "0                                global/Variable:0             []          1\n",
       "1  gpu/embedding/embedding_layer/embedding_table:0      [26, 512]      13312\n",
       "2                      gpu/mlp/fully_connected/W:0      [51, 512]      26112\n",
       "3                      gpu/mlp/fully_connected/B:0          [512]        512\n",
       "4            gpu/mlp/highway/output_lin_0/Matrix:0     [512, 512]     262144\n",
       "5         gpu/mlp/highway/transform_lin_0/Matrix:0     [512, 512]     262144\n",
       "6          gpu/mlp/highway_1/output_lin_0/Matrix:0     [512, 512]     262144\n",
       "7       gpu/mlp/highway_1/transform_lin_0/Matrix:0     [512, 512]     262144"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 ... training ...\n",
      "Minibatch 500 / loss: 0.589347\n",
      "Minibatch 500 / accuracy: 0.744141\n",
      "Minibatch 1000 / loss: 0.67645\n",
      "Minibatch 1000 / accuracy: 0.732422\n",
      "Minibatch 1500 / loss: 0.509177\n",
      "Minibatch 1500 / accuracy: 0.771484\n",
      "Minibatch 2000 / loss: 0.459651\n",
      "Minibatch 2000 / accuracy: 0.789062\n",
      "Minibatch 2500 / loss: 0.570081\n",
      "Minibatch 2500 / accuracy: 0.767578\n",
      "Minibatch 3000 / loss: 0.527987\n",
      "Minibatch 3000 / accuracy: 0.763672\n",
      "Minibatch 3500 / loss: 0.493769\n",
      "Minibatch 3500 / accuracy: 0.78125\n",
      "Minibatch 4000 / loss: 0.522761\n",
      "Minibatch 4000 / accuracy: 0.748047\n",
      "Minibatch 4500 / loss: 0.549168\n",
      "Minibatch 4500 / accuracy: 0.746094\n",
      "Minibatch 5000 / loss: 0.527923\n",
      "Minibatch 5000 / accuracy: 0.738281\n",
      "Minibatch 5500 / loss: 0.500128\n",
      "Minibatch 5500 / accuracy: 0.757812\n",
      "epoch time: 0.8756827473640442\n",
      "Epoch 1 training accuracy: 0.763022616077\n",
      "Epoch 1 ... test ...\n",
      "Minibatch 500 / loss: 0.430982\n",
      "Minibatch 500 / accuracy: 0.84375\n",
      "Minibatch 1000 / loss: 0.392171\n",
      "Minibatch 1000 / accuracy: 0.871094\n",
      "Epoch 1 test accuracy: 0.771131030552\n",
      "Model saved in file: model/user_rank_model_1.ckpt\n",
      "{'loss': 0.52656407609105671, 'valid_los': 0.50840958259054558, 'best_accuracy': 0.76302261607714161, 'best_test_accuracy': 0.77113103055162813, 'epoch': 0, 'learning_rate': 0.01, 'valid_perplexity': 1.6626447918382443}\n",
      "Epoch 2 ... training ...\n",
      "Minibatch 500 / loss: 0.478394\n",
      "Minibatch 500 / accuracy: 0.789062\n",
      "Minibatch 1000 / loss: 0.481504\n",
      "Minibatch 1000 / accuracy: 0.78125\n",
      "Minibatch 1500 / loss: 0.494178\n",
      "Minibatch 1500 / accuracy: 0.78125\n",
      "Minibatch 2000 / loss: 0.469998\n",
      "Minibatch 2000 / accuracy: 0.789062\n",
      "Minibatch 2500 / loss: 0.543539\n",
      "Minibatch 2500 / accuracy: 0.755859\n",
      "Minibatch 3000 / loss: 0.481458\n",
      "Minibatch 3000 / accuracy: 0.794922\n",
      "Minibatch 3500 / loss: 0.499671\n",
      "Minibatch 3500 / accuracy: 0.785156\n",
      "Minibatch 4000 / loss: 0.520427\n",
      "Minibatch 4000 / accuracy: 0.769531\n",
      "Minibatch 4500 / loss: 0.546539\n",
      "Minibatch 4500 / accuracy: 0.751953\n",
      "Minibatch 5000 / loss: 0.457633\n",
      "Minibatch 5000 / accuracy: 0.796875\n",
      "Minibatch 5500 / loss: 0.524769\n",
      "Minibatch 5500 / accuracy: 0.769531\n",
      "epoch time: 0.8364725708961487\n",
      "Epoch 2 training accuracy: 0.773243719386\n",
      "Epoch 2 ... test ...\n",
      "Minibatch 500 / loss: 0.421521\n",
      "Minibatch 500 / accuracy: 0.853516\n",
      "Minibatch 1000 / loss: 0.423638\n",
      "Minibatch 1000 / accuracy: 0.845703\n",
      "Epoch 2 test accuracy: 0.774266107084\n",
      "Model saved in file: model/user_rank_model_1.ckpt\n",
      "{'loss': 0.50242093698569656, 'valid_los': 0.49990988750607734, 'best_accuracy': 0.77324371938628678, 'best_test_accuracy': 0.77426610708437882, 'epoch': 1, 'learning_rate': 0.01, 'valid_perplexity': 1.648572707008465}\n",
      "Epoch 3 ... training ...\n",
      "Minibatch 500 / loss: 0.460932\n",
      "Minibatch 500 / accuracy: 0.789062\n",
      "Minibatch 1000 / loss: 0.486533\n",
      "Minibatch 1000 / accuracy: 0.791016\n",
      "Minibatch 1500 / loss: 0.51783\n",
      "Minibatch 1500 / accuracy: 0.767578\n",
      "Minibatch 2000 / loss: 0.490742\n",
      "Minibatch 2000 / accuracy: 0.78125\n",
      "Minibatch 2500 / loss: 0.503843\n",
      "Minibatch 2500 / accuracy: 0.771484\n",
      "Minibatch 3000 / loss: 0.483292\n",
      "Minibatch 3000 / accuracy: 0.796875\n",
      "Minibatch 3500 / loss: 0.543814\n",
      "Minibatch 3500 / accuracy: 0.742188\n",
      "Minibatch 4000 / loss: 0.532225\n",
      "Minibatch 4000 / accuracy: 0.763672\n",
      "Minibatch 4500 / loss: 0.47809\n",
      "Minibatch 4500 / accuracy: 0.78125\n",
      "Minibatch 5000 / loss: 0.477505\n",
      "Minibatch 5000 / accuracy: 0.777344\n",
      "Minibatch 5500 / loss: 0.461605\n",
      "Minibatch 5500 / accuracy: 0.798828\n",
      "epoch time: 0.8358740290006001\n",
      "Epoch 3 training accuracy: 0.776479028297\n",
      "Epoch 3 ... test ...\n",
      "Minibatch 500 / loss: 0.43392\n",
      "Minibatch 500 / accuracy: 0.853516\n",
      "Minibatch 1000 / loss: 0.397649\n",
      "Minibatch 1000 / accuracy: 0.855469\n",
      "Epoch 3 test accuracy: 0.778419664362\n",
      "Model saved in file: model/user_rank_model_1.ckpt\n",
      "{'loss': 0.49623370994196492, 'valid_los': 0.49433199398691202, 'best_accuracy': 0.77647902829664117, 'best_test_accuracy': 0.77841966436239474, 'epoch': 2, 'learning_rate': 0.01, 'valid_perplexity': 1.6394027423088384}\n",
      "Epoch 4 ... training ...\n",
      "Minibatch 500 / loss: 0.458074\n",
      "Minibatch 500 / accuracy: 0.798828\n",
      "Minibatch 1000 / loss: 0.481254\n",
      "Minibatch 1000 / accuracy: 0.785156\n",
      "Minibatch 1500 / loss: 0.532546\n",
      "Minibatch 1500 / accuracy: 0.767578\n",
      "Minibatch 2000 / loss: 0.458535\n",
      "Minibatch 2000 / accuracy: 0.792969\n",
      "Minibatch 2500 / loss: 0.492847\n",
      "Minibatch 2500 / accuracy: 0.767578\n",
      "Minibatch 3000 / loss: 0.544032\n",
      "Minibatch 3000 / accuracy: 0.744141\n",
      "Minibatch 3500 / loss: 0.504031\n",
      "Minibatch 3500 / accuracy: 0.777344\n",
      "Minibatch 4000 / loss: 0.46164\n",
      "Minibatch 4000 / accuracy: 0.792969\n",
      "Minibatch 4500 / loss: 0.508803\n",
      "Minibatch 4500 / accuracy: 0.755859\n",
      "Minibatch 5000 / loss: 0.427177\n",
      "Minibatch 5000 / accuracy: 0.8125\n",
      "Minibatch 5500 / loss: 0.48796\n",
      "Minibatch 5500 / accuracy: 0.771484\n",
      "epoch time: 0.8330081224441528\n",
      "Epoch 4 training accuracy: 0.780016457709\n",
      "Epoch 4 ... test ...\n",
      "Minibatch 500 / loss: 0.445396\n",
      "Minibatch 500 / accuracy: 0.828125\n",
      "Minibatch 1000 / loss: 0.392183\n",
      "Minibatch 1000 / accuracy: 0.855469\n",
      "Epoch 4 test accuracy: 0.780329490396\n",
      "Model saved in file: model/user_rank_model_1.ckpt\n",
      "{'loss': 0.49100519158281802, 'valid_los': 0.4904972358516399, 'best_accuracy': 0.78001645770871808, 'best_test_accuracy': 0.78032949039638322, 'epoch': 3, 'learning_rate': 0.01, 'valid_perplexity': 1.6331280679243851}\n",
      "Epoch 5 ... training ...\n",
      "Minibatch 500 / loss: 0.484607\n",
      "Minibatch 500 / accuracy: 0.789062\n",
      "Minibatch 1000 / loss: 0.504488\n",
      "Minibatch 1000 / accuracy: 0.767578\n",
      "Minibatch 1500 / loss: 0.466953\n",
      "Minibatch 1500 / accuracy: 0.789062\n",
      "Minibatch 2000 / loss: 0.481461\n",
      "Minibatch 2000 / accuracy: 0.777344\n",
      "Minibatch 2500 / loss: 0.479028\n",
      "Minibatch 2500 / accuracy: 0.783203\n",
      "Minibatch 3000 / loss: 0.462408\n",
      "Minibatch 3000 / accuracy: 0.806641\n",
      "Minibatch 3500 / loss: 0.476808\n",
      "Minibatch 3500 / accuracy: 0.783203\n",
      "Minibatch 4000 / loss: 0.478246\n",
      "Minibatch 4000 / accuracy: 0.773438\n",
      "Minibatch 4500 / loss: 0.496659\n",
      "Minibatch 4500 / accuracy: 0.783203\n",
      "Minibatch 5000 / loss: 0.545053\n",
      "Minibatch 5000 / accuracy: 0.742188\n",
      "Minibatch 5500 / loss: 0.518912\n",
      "Minibatch 5500 / accuracy: 0.755859\n",
      "epoch time: 0.8350702047348022\n",
      "Epoch 5 training accuracy: 0.781711825241\n",
      "Epoch 5 ... test ...\n",
      "Minibatch 500 / loss: 0.449504\n",
      "Minibatch 500 / accuracy: 0.833984\n",
      "Minibatch 1000 / loss: 0.405983\n",
      "Minibatch 1000 / accuracy: 0.841797\n",
      "Epoch 5 test accuracy: 0.782268655382\n",
      "Model saved in file: model/user_rank_model_1.ckpt\n",
      "{'loss': 0.48873636266475173, 'valid_los': 0.48909713044097841, 'best_accuracy': 0.78171182524092797, 'best_test_accuracy': 0.78226865538188139, 'epoch': 4, 'learning_rate': 0.01, 'valid_perplexity': 1.6308431164399144}\n",
      "Epoch 6 ... training ...\n",
      "Minibatch 500 / loss: 0.484088\n",
      "Minibatch 500 / accuracy: 0.785156\n",
      "Minibatch 1000 / loss: 0.480946\n",
      "Minibatch 1000 / accuracy: 0.761719\n",
      "Minibatch 1500 / loss: 0.492809\n",
      "Minibatch 1500 / accuracy: 0.789062\n",
      "Minibatch 2000 / loss: 0.46725\n",
      "Minibatch 2000 / accuracy: 0.8125\n",
      "Minibatch 2500 / loss: 0.453683\n",
      "Minibatch 2500 / accuracy: 0.804688\n",
      "Minibatch 3000 / loss: 0.537361\n",
      "Minibatch 3000 / accuracy: 0.740234\n",
      "Minibatch 3500 / loss: 0.477857\n",
      "Minibatch 3500 / accuracy: 0.791016\n",
      "Minibatch 4000 / loss: 0.531382\n",
      "Minibatch 4000 / accuracy: 0.755859\n",
      "Minibatch 4500 / loss: 0.467036\n",
      "Minibatch 4500 / accuracy: 0.796875\n",
      "Minibatch 5000 / loss: 0.528059\n",
      "Minibatch 5000 / accuracy: 0.767578\n",
      "Minibatch 5500 / loss: 0.495637\n",
      "Minibatch 5500 / accuracy: 0.769531\n",
      "epoch time: 0.8367456714312236\n",
      "Epoch 6 training accuracy: 0.778499219027\n",
      "Epoch 6 ... test ...\n",
      "Minibatch 500 / loss: 0.403917\n",
      "Minibatch 500 / accuracy: 0.871094\n",
      "Minibatch 1000 / loss: 0.427796\n",
      "Minibatch 1000 / accuracy: 0.830078\n",
      "Epoch 6 test accuracy: 0.771070955556\n",
      "{'loss': 0.49432912832821535, 'valid_los': 0.50964365223842234, 'best_accuracy': 0.78171182524092797, 'best_test_accuracy': 0.78226865538188139, 'epoch': 5, 'learning_rate': 0.01, 'valid_perplexity': 1.6646978778760757}\n",
      "Epoch 7 ... training ...\n",
      "Minibatch 500 / loss: 0.500246\n",
      "Minibatch 500 / accuracy: 0.757812\n",
      "Minibatch 1000 / loss: 0.521267\n",
      "Minibatch 1000 / accuracy: 0.763672\n",
      "Minibatch 1500 / loss: 0.508605\n",
      "Minibatch 1500 / accuracy: 0.767578\n",
      "Minibatch 2000 / loss: 0.509538\n",
      "Minibatch 2000 / accuracy: 0.765625\n",
      "Minibatch 2500 / loss: 0.503021\n",
      "Minibatch 2500 / accuracy: 0.775391\n",
      "Minibatch 3000 / loss: 0.464588\n",
      "Minibatch 3000 / accuracy: 0.794922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch 3500 / loss: 0.50132\n",
      "Minibatch 3500 / accuracy: 0.777344\n",
      "Minibatch 4000 / loss: 0.499854\n",
      "Minibatch 4000 / accuracy: 0.775391\n",
      "Minibatch 4500 / loss: 0.527694\n",
      "Minibatch 4500 / accuracy: 0.757812\n",
      "Minibatch 5000 / loss: 0.489904\n",
      "Minibatch 5000 / accuracy: 0.761719\n",
      "Minibatch 5500 / loss: 0.454524\n",
      "Minibatch 5500 / accuracy: 0.794922\n",
      "epoch time: 0.8354515353838603\n",
      "Epoch 7 training accuracy: 0.772868251711\n",
      "Epoch 7 ... test ...\n",
      "Minibatch 500 / loss: 0.448714\n",
      "Minibatch 500 / accuracy: 0.835938\n",
      "Minibatch 1000 / loss: 0.406151\n",
      "Minibatch 1000 / accuracy: 0.839844\n",
      "Epoch 7 test accuracy: 0.773053430422\n",
      "{'loss': 0.50333869349822713, 'valid_los': 0.50402581059331741, 'best_accuracy': 0.78171182524092797, 'best_test_accuracy': 0.78226865538188139, 'epoch': 6, 'learning_rate': 0.006666666666666667, 'valid_perplexity': 1.6553720887414378}\n",
      "Epoch 8 ... training ...\n",
      "Minibatch 500 / loss: 0.510713\n",
      "Minibatch 500 / accuracy: 0.796875\n",
      "Minibatch 1000 / loss: 0.506873\n",
      "Minibatch 1000 / accuracy: 0.773438\n",
      "Minibatch 1500 / loss: 0.501573\n",
      "Minibatch 1500 / accuracy: 0.777344\n",
      "Minibatch 2000 / loss: 0.510198\n",
      "Minibatch 2000 / accuracy: 0.757812\n",
      "Minibatch 2500 / loss: 0.537085\n",
      "Minibatch 2500 / accuracy: 0.746094\n",
      "Minibatch 3000 / loss: 0.534513\n",
      "Minibatch 3000 / accuracy: 0.759766\n",
      "Minibatch 3500 / loss: 0.505626\n",
      "Minibatch 3500 / accuracy: 0.767578\n",
      "Minibatch 4000 / loss: 0.529807\n",
      "Minibatch 4000 / accuracy: 0.757812\n",
      "Minibatch 4500 / loss: 0.489471\n",
      "Minibatch 4500 / accuracy: 0.777344\n",
      "Minibatch 5000 / loss: 0.475137\n",
      "Minibatch 5000 / accuracy: 0.779297\n",
      "Minibatch 5500 / loss: 0.511078\n",
      "Minibatch 5500 / accuracy: 0.757812\n",
      "epoch time: 0.8378870328267415\n",
      "Epoch 8 training accuracy: 0.772715270462\n",
      "Epoch 8 ... test ...\n",
      "Minibatch 500 / loss: 0.438937\n",
      "Minibatch 500 / accuracy: 0.833984\n",
      "Minibatch 1000 / loss: 0.410421\n",
      "Minibatch 1000 / accuracy: 0.839844\n",
      "Epoch 8 test accuracy: 0.769345545788\n",
      "{'loss': 0.50274388284570271, 'valid_los': 0.50570284601800575, 'best_accuracy': 0.78171182524092797, 'best_test_accuracy': 0.78226865538188139, 'epoch': 7, 'learning_rate': 0.006666666666666667, 'valid_perplexity': 1.6581505355009316}\n",
      "Epoch 9 ... training ...\n",
      "Minibatch 500 / loss: 0.509806\n",
      "Minibatch 500 / accuracy: 0.779297\n",
      "Minibatch 1000 / loss: 0.518736\n",
      "Minibatch 1000 / accuracy: 0.765625\n",
      "Minibatch 1500 / loss: 0.52983\n",
      "Minibatch 1500 / accuracy: 0.753906\n",
      "Minibatch 2000 / loss: 0.476695\n",
      "Minibatch 2000 / accuracy: 0.810547\n",
      "Minibatch 2500 / loss: 0.467485\n",
      "Minibatch 2500 / accuracy: 0.791016\n",
      "Minibatch 3000 / loss: 0.4816\n",
      "Minibatch 3000 / accuracy: 0.802734\n",
      "Minibatch 3500 / loss: 0.517663\n",
      "Minibatch 3500 / accuracy: 0.759766\n",
      "Minibatch 4000 / loss: 0.477243\n",
      "Minibatch 4000 / accuracy: 0.777344\n",
      "Minibatch 4500 / loss: 0.498288\n",
      "Minibatch 4500 / accuracy: 0.761719\n",
      "Minibatch 5000 / loss: 0.511021\n",
      "Minibatch 5000 / accuracy: 0.75\n",
      "Minibatch 5500 / loss: 0.494354\n",
      "Minibatch 5500 / accuracy: 0.777344\n",
      "epoch time: 0.8333625555038452\n",
      "Epoch 9 training accuracy: 0.775278230279\n",
      "Epoch 9 ... test ...\n",
      "Minibatch 500 / loss: 0.442857\n",
      "Minibatch 500 / accuracy: 0.839844\n",
      "Minibatch 1000 / loss: 0.426288\n",
      "Minibatch 1000 / accuracy: 0.832031\n",
      "Epoch 9 test accuracy: 0.77600967906\n",
      "{'loss': 0.49818046618066597, 'valid_los': 0.4984461707079908, 'best_accuracy': 0.78171182524092797, 'best_test_accuracy': 0.78226865538188139, 'epoch': 8, 'learning_rate': 0.0044444444444444444, 'valid_perplexity': 1.64616142858922}\n",
      "Epoch 10 ... training ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9ca767954c93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0muser_rank_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_rank_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0muser_rank_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/ceph/jenkins/wei.wang/tftools/tf_object.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, input_list, train_idxs, test_idxs, run_type, shuffle)\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'... training ...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m             \u001b[0mepochLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochMetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m             \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch time:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/ceph/jenkins/wei.wang/tftools/tf_object.py\u001b[0m in \u001b[0;36mmodel_run\u001b[0;34m(self, input_list, idxs, run_type, mode, shuffle, save_metric)\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0;31m#print('model training...')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_step\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_step\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'{}_prediction'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeedDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'{}_prediction'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeedDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/CORP/jenkins/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/CORP/jenkins/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/CORP/jenkins/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/CORP/jenkins/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/CORP/jenkins/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "graph_to_use = tf.Graph()\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth=True\n",
    "res = {}\n",
    "with tf.Session(graph=graph_to_use, config=config) as session:\n",
    "    #cnn_model = TextCNN(FLAGS, session, current_task_name='text_cnn_model')\n",
    "    #cnn_model.build_model(num_classes=len(set(label[idxs])),max_conv_len=7, num_filters=512, dropout_keep_prob=0.5)\n",
    "    user_rank_model = UserRankModel(FLAGS, session, current_task_name='user_rank_model_1')\n",
    "    #label[idxs]\n",
    "    user_rank_model.build_model(net_size=512)\n",
    "    user_rank_model.build_model_summary()\n",
    "    display(user_rank_model.model_summary())\n",
    "    user_rank_model.run([data,event,label], train_idxs, test_idxs)\n",
    "    for var in tf.trainable_variables():\n",
    "        res[var.name] = var.eval()\n",
    "    with open('param1.pickle', 'wb') as output_file:\n",
    "        pkl.dump(res, output_file)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
