{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "sys.path.append('../tftools/')\n",
    "\n",
    "from tf_object import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UserRankModel(TFModel):\n",
    "    def __init__(self, config, sess, current_task_name='user_rank'):\n",
    "        super(UserRankModel, self).__init__(config, sess)\n",
    "        #self.net_size = config.net_size\n",
    "        self.feature_num = config.feature_num\n",
    "        self.event_num = config.event_num\n",
    "        self.current_task_name = current_task_name\n",
    "        self.init_scale = config.init_scale\n",
    "        \n",
    "    def build_input(self):\n",
    "        with tf.name_scope('input'):\n",
    "            inputX = tf.placeholder(tf.float32, [None, self.feature_num], name=\"input_feature\")\n",
    "            eventID = tf.placeholder(tf.int32, [None, 1], name='event')\n",
    "            inputLabel = tf.placeholder(tf.float32, [None], name='label')\n",
    "            tf.add_to_collection(tf.GraphKeys.INPUTS, inputX)\n",
    "            tf.add_to_collection(tf.GraphKeys.INPUTS, eventID)\n",
    "            tf.add_to_collection(tf.GraphKeys.INPUTS, inputLabel)\n",
    "            self.split_inputX = tf.split(inputX, self.gpu_num, 0)\n",
    "            self.split_eventID = tf.split(eventID, self.gpu_num, 0)\n",
    "            self.split_inputLabel = tf.split(inputLabel, self.gpu_num, 0)\n",
    "        self.__build_global_setting__()\n",
    "        with tf.name_scope('states_array'):\n",
    "            self.last_flat = [[] for i in range(0,self.gpu_num)]\n",
    "     \n",
    "    def build_mlp_model(self, gpu_id=0, layer_num=3,net_size=512):\n",
    "        with get_new_variable_scope('embedding') as embedding_scope:\n",
    "            event_embedding = my_embedding_layer(self.split_eventID[gpu_id], self.event_num, net_size, \n",
    "                                  layer_name='embedding_layer', init_scale=self.init_scale)\n",
    "        dense = self.split_inputX[gpu_id]\n",
    "        with get_new_variable_scope('mlp') as mlp_scope:\n",
    "            for i in range(0, layer_num):            \n",
    "                dense = my_full_connected(highway(dense), net_size, act=tf.nn.tanh)\n",
    "        with tf.name_scope(\"dropout\"):\n",
    "            self.last_flat[gpu_id] = tf.reshape(tf.matmul(event_embedding, tf.reshape(dense, [-1,1,net_size]), adjoint_b=True), [-1])\n",
    "            \n",
    "    def build_prediction(self, gpu_id=0, accK=1):\n",
    "        prediction = self.last_flat[gpu_id]\n",
    "        #prediction = tf.nn.sigmoid(self.last_flat[gpu_id])\n",
    "        self.tower_prediction_results.append(prediction)\n",
    "        self.params = tf.trainable_variables()[1:]\n",
    "        with tf.name_scope('loss'): \n",
    "            #loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.split_inputLabel[gpu_id], logits=prediction)\n",
    "            loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=self.split_inputLabel[gpu_id],logits=prediction)\n",
    "            grads, capped_gvs = my_compute_grad(self.opt, loss, self.params, \n",
    "                                                clip_type = 'clip_norm', \n",
    "                                                max_clip_grad=self.clip_gradients)           \n",
    "        with tf.name_scope('accuracy'):\n",
    "            accuracy = tf.to_float(tf.equal(tf.cast(prediction>0.5,tf.int32), tf.cast(self.split_inputLabel[gpu_id],tf.int32)))\n",
    "            #accuracy = tf.to_float(tf.nn.in_top_k(prediction, self.split_inputLabel[gpu_id],k=accK))\n",
    "        self.__add_to_tower_list__(grads,capped_gvs,loss,accuracy)\n",
    "              \n",
    "    def build_model(self,*args, **kwargs):\n",
    "        self.build_input()\n",
    "        for idx, gpu_id in enumerate(self.gpus):\n",
    "            with tf.device('/gpu:%d' % gpu_id):\n",
    "                with tf.name_scope('Tower_%d' % (gpu_id)) as tower_scope:\n",
    "                    gpu_scope = tf.variable_scope('gpu', reuse=(idx!=0))\n",
    "                    with gpu_scope as gpu_scope:\n",
    "                        self.build_mlp_model(gpu_id=idx, *args, **kwargs)\n",
    "                        self.build_prediction(gpu_id=idx)                       \n",
    "        self.build_model_aggregation()          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "\n",
    "flags.DEFINE_integer(\"feature_num\", 52, \"term number in input sequence(zero mask) [20001]\")\n",
    "flags.DEFINE_integer(\"event_num\", 26, \"the max length of input sequence [80]\")\n",
    "flags.DEFINE_float(\"init_scale\", 1.0, \"init scale for embedding layer\")\n",
    "flags.DEFINE_float(\"learning_rate\", 0.01, \"learning rate [0.001]\")\n",
    "flags.DEFINE_string(\"opt\", 'sgd', \"optimizer\")\n",
    "flags.DEFINE_integer(\"batch_size\", 512, \"batch size to use during training [128]\")\n",
    "flags.DEFINE_float(\"clip_gradients\", 5.0, \"clip gradients to this norm [5.0]\")\n",
    "flags.DEFINE_integer(\"n_epochs\", 100, \"number of epoch to use during training [10]\")\n",
    "flags.DEFINE_boolean(\"epoch_save\", True, \"save checkpoint or not in each epoch [True]\")\n",
    "flags.DEFINE_integer(\"print_step\", 100, \"print step duraing training [100]\")\n",
    "flags.DEFINE_string(\"logs_dir\", \"logs/\", \"logs directory [logs/]\")\n",
    "flags.DEFINE_string(\"model_dir\", \"model/\", \"model directory [model/]\")\n",
    "flags.DEFINE_boolean(\"dir_clear\", False, \"clear the log and model directory\")\n",
    "flags.DEFINE_boolean(\"lr_annealing\", True, \"use lr annealing or not after each epoch [False]\")\n",
    "flags.DEFINE_integer(\"gpu_id\", 0, \"default gpu id [0]\")\n",
    "flags.DEFINE_integer(\"gpu_num\", 4, \"gpu_num\")\n",
    "\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load('train_data.npy')\n",
    "label = data[:,-2]\n",
    "event = data[:,-1:]\n",
    "data = data[:,:-2]\n",
    "data = scale(data, axis=0, with_mean=True, with_std=True, copy=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idxs = np.append(np.random.choice(np.where(label==1)[0],200000), np.random.choice(np.where(label==0)[0],200000))\n",
    "train_idxs, test_idxs = train_test_split(idxs, test_size=0.2, random_state=42)\n",
    "test_idxs = np.sort(test_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>variable_shape</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>global/Variable:0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpu/embedding/embedding_layer/embedding_table:0</td>\n",
       "      <td>[26, 512]</td>\n",
       "      <td>13312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpu/mlp/highway/output_lin_0/Matrix:0</td>\n",
       "      <td>[52, 52]</td>\n",
       "      <td>2704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpu/mlp/highway/transform_lin_0/Matrix:0</td>\n",
       "      <td>[52, 52]</td>\n",
       "      <td>2704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpu/mlp/fully_connected/W:0</td>\n",
       "      <td>[52, 512]</td>\n",
       "      <td>26624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpu/mlp/fully_connected/B:0</td>\n",
       "      <td>[512]</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpu/mlp/highway_1/output_lin_0/Matrix:0</td>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>262144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpu/mlp/highway_1/transform_lin_0/Matrix:0</td>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>262144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpu/mlp/fully_connected_1/W:0</td>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>262144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpu/mlp/fully_connected_1/B:0</td>\n",
       "      <td>[512]</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpu/mlp/highway_2/output_lin_0/Matrix:0</td>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>262144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpu/mlp/highway_2/transform_lin_0/Matrix:0</td>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>262144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpu/mlp/fully_connected_2/W:0</td>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>262144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gpu/mlp/fully_connected_2/B:0</td>\n",
       "      <td>[512]</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      variable_name variable_shape parameters\n",
       "0                                 global/Variable:0             []          1\n",
       "1   gpu/embedding/embedding_layer/embedding_table:0      [26, 512]      13312\n",
       "2             gpu/mlp/highway/output_lin_0/Matrix:0       [52, 52]       2704\n",
       "3          gpu/mlp/highway/transform_lin_0/Matrix:0       [52, 52]       2704\n",
       "4                       gpu/mlp/fully_connected/W:0      [52, 512]      26624\n",
       "5                       gpu/mlp/fully_connected/B:0          [512]        512\n",
       "6           gpu/mlp/highway_1/output_lin_0/Matrix:0     [512, 512]     262144\n",
       "7        gpu/mlp/highway_1/transform_lin_0/Matrix:0     [512, 512]     262144\n",
       "8                     gpu/mlp/fully_connected_1/W:0     [512, 512]     262144\n",
       "9                     gpu/mlp/fully_connected_1/B:0          [512]        512\n",
       "10          gpu/mlp/highway_2/output_lin_0/Matrix:0     [512, 512]     262144\n",
       "11       gpu/mlp/highway_2/transform_lin_0/Matrix:0     [512, 512]     262144\n",
       "12                    gpu/mlp/fully_connected_2/W:0     [512, 512]     262144\n",
       "13                    gpu/mlp/fully_connected_2/B:0          [512]        512"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 ... training ...\n",
      "Minibatch 100 / loss: 0.684452\n",
      "Minibatch 100 / accuracy: 0.568359\n",
      "Minibatch 200 / loss: 0.663335\n",
      "Minibatch 200 / accuracy: 0.554688\n",
      "Minibatch 300 / loss: 0.676609\n",
      "Minibatch 300 / accuracy: 0.568359\n",
      "Minibatch 400 / loss: 0.648458\n",
      "Minibatch 400 / accuracy: 0.626953\n",
      "Minibatch 500 / loss: 0.664216\n",
      "Minibatch 500 / accuracy: 0.597656\n",
      "Minibatch 600 / loss: 0.644684\n",
      "Minibatch 600 / accuracy: 0.578125\n",
      "epoch time: 0.1859108289082845\n",
      "Epoch 1 training accuracy: 0.5675625\n",
      "Epoch 1 ... test ...\n",
      "Minibatch 100 / loss: 0.670924\n",
      "Minibatch 100 / accuracy: 0.585938\n",
      "Epoch 1 test accuracy: 0.592825\n",
      "Model saved in file: model/user_rank_model.ckpt\n",
      "{'loss': 0.67300595703124999, 'valid_los': 0.66357470703124999, 'best_accuracy': 0.56756249999999997, 'best_test_accuracy': 0.59282500000000005, 'epoch': 0, 'learning_rate': 0.01, 'valid_perplexity': 1.941721026808351}\n",
      "Epoch 2 ... training ...\n",
      "Minibatch 100 / loss: 0.657644\n",
      "Minibatch 100 / accuracy: 0.5625\n",
      "Minibatch 200 / loss: 0.646289\n",
      "Minibatch 200 / accuracy: 0.595703\n",
      "Minibatch 300 / loss: 0.697495\n",
      "Minibatch 300 / accuracy: 0.529297\n",
      "Minibatch 400 / loss: 0.667646\n",
      "Minibatch 400 / accuracy: 0.578125\n",
      "Minibatch 500 / loss: 0.642529\n",
      "Minibatch 500 / accuracy: 0.607422\n",
      "Minibatch 600 / loss: 0.626373\n",
      "Minibatch 600 / accuracy: 0.617188\n",
      "epoch time: 0.15045941670735677\n",
      "Epoch 2 training accuracy: 0.58008125\n",
      "Epoch 2 ... test ...\n",
      "Minibatch 100 / loss: 0.669621\n",
      "Minibatch 100 / accuracy: 0.595703\n",
      "Epoch 2 test accuracy: 0.593\n",
      "Model saved in file: model/user_rank_model.ckpt\n",
      "{'loss': 0.65868359374999996, 'valid_los': 0.65677177734375003, 'best_accuracy': 0.58008124999999999, 'best_test_accuracy': 0.59299999999999997, 'epoch': 1, 'learning_rate': 0.01, 'valid_perplexity': 1.928556464756363}\n",
      "Epoch 3 ... training ...\n",
      "Minibatch 100 / loss: 0.62531\n",
      "Minibatch 100 / accuracy: 0.615234\n",
      "Minibatch 200 / loss: 0.666902\n",
      "Minibatch 200 / accuracy: 0.59375\n",
      "Minibatch 300 / loss: 0.647708\n",
      "Minibatch 300 / accuracy: 0.587891\n",
      "Minibatch 400 / loss: 0.657445\n",
      "Minibatch 400 / accuracy: 0.601562\n",
      "Minibatch 500 / loss: 0.647015\n",
      "Minibatch 500 / accuracy: 0.580078\n",
      "Minibatch 600 / loss: 0.646196\n",
      "Minibatch 600 / accuracy: 0.603516\n",
      "epoch time: 0.14860047101974488\n",
      "Epoch 3 training accuracy: 0.586540625\n",
      "Epoch 3 ... test ...\n",
      "Minibatch 100 / loss: 0.679762\n",
      "Minibatch 100 / accuracy: 0.587891\n",
      "Epoch 3 test accuracy: 0.585575\n",
      "{'loss': 0.65294716796874996, 'valid_los': 0.65545058593750005, 'best_accuracy': 0.58654062500000004, 'best_test_accuracy': 0.59299999999999997, 'epoch': 2, 'learning_rate': 0.01, 'valid_perplexity': 1.9260101549803479}\n",
      "Epoch 4 ... training ...\n",
      "Minibatch 100 / loss: 0.65061\n",
      "Minibatch 100 / accuracy: 0.617188\n",
      "Minibatch 200 / loss: 0.650541\n",
      "Minibatch 200 / accuracy: 0.615234\n",
      "Minibatch 300 / loss: 0.677512\n",
      "Minibatch 300 / accuracy: 0.566406\n",
      "Minibatch 400 / loss: 0.646794\n",
      "Minibatch 400 / accuracy: 0.587891\n",
      "Minibatch 500 / loss: 0.648711\n",
      "Minibatch 500 / accuracy: 0.605469\n",
      "Minibatch 600 / loss: 0.664332\n",
      "Minibatch 600 / accuracy: 0.572266\n",
      "epoch time: 0.14942102432250975\n",
      "Epoch 4 training accuracy: 0.590140625\n",
      "Epoch 4 ... test ...\n",
      "Minibatch 100 / loss: 0.662024\n",
      "Minibatch 100 / accuracy: 0.587891\n",
      "Epoch 4 test accuracy: 0.5817\n",
      "{'loss': 0.64889682617187505, 'valid_los': 0.65239042968750005, 'best_accuracy': 0.59014062499999997, 'best_test_accuracy': 0.59299999999999997, 'epoch': 3, 'learning_rate': 0.01, 'valid_perplexity': 1.920125271890348}\n",
      "Epoch 5 ... training ...\n",
      "Minibatch 100 / loss: 0.655646\n",
      "Minibatch 100 / accuracy: 0.568359\n",
      "Minibatch 200 / loss: 0.614776\n",
      "Minibatch 200 / accuracy: 0.621094\n",
      "Minibatch 300 / loss: 0.650997\n",
      "Minibatch 300 / accuracy: 0.568359\n",
      "Minibatch 400 / loss: 0.670587\n",
      "Minibatch 400 / accuracy: 0.552734\n",
      "Minibatch 500 / loss: 0.644485\n",
      "Minibatch 500 / accuracy: 0.605469\n",
      "Minibatch 600 / loss: 0.620983\n",
      "Minibatch 600 / accuracy: 0.585938\n",
      "epoch time: 0.14918012619018556\n",
      "Epoch 5 training accuracy: 0.5921875\n",
      "Epoch 5 ... test ...\n",
      "Minibatch 100 / loss: 0.663999\n",
      "Minibatch 100 / accuracy: 0.583984\n",
      "Epoch 5 test accuracy: 0.5832625\n",
      "{'loss': 0.646184521484375, 'valid_los': 0.6544322265625, 'best_accuracy': 0.59218749999999998, 'best_test_accuracy': 0.59299999999999997, 'epoch': 4, 'learning_rate': 0.01, 'valid_perplexity': 1.9240497828337733}\n",
      "Epoch 6 ... training ...\n",
      "Minibatch 100 / loss: 0.639621\n",
      "Minibatch 100 / accuracy: 0.621094\n",
      "Minibatch 200 / loss: 0.639934\n",
      "Minibatch 200 / accuracy: 0.587891\n",
      "Minibatch 300 / loss: 0.649747\n",
      "Minibatch 300 / accuracy: 0.564453\n",
      "Minibatch 400 / loss: 0.637923\n",
      "Minibatch 400 / accuracy: 0.578125\n",
      "Minibatch 500 / loss: 0.62432\n",
      "Minibatch 500 / accuracy: 0.611328\n",
      "Minibatch 600 / loss: 0.660141\n",
      "Minibatch 600 / accuracy: 0.583984\n",
      "epoch time: 0.14589625199635822\n",
      "Epoch 6 training accuracy: 0.59675625\n",
      "Epoch 6 ... test ...\n",
      "Minibatch 100 / loss: 0.655983\n",
      "Minibatch 100 / accuracy: 0.587891\n",
      "Epoch 6 test accuracy: 0.5886375\n",
      "{'loss': 0.64087304687500002, 'valid_los': 0.64900244140624996, 'best_accuracy': 0.59675624999999999, 'best_test_accuracy': 0.59299999999999997, 'epoch': 5, 'learning_rate': 0.006666666666666667, 'valid_perplexity': 1.913630917580899}\n",
      "Epoch 7 ... training ...\n",
      "Minibatch 100 / loss: 0.649437\n",
      "Minibatch 100 / accuracy: 0.574219\n",
      "Minibatch 200 / loss: 0.621831\n",
      "Minibatch 200 / accuracy: 0.636719\n",
      "Minibatch 300 / loss: 0.639494\n",
      "Minibatch 300 / accuracy: 0.607422\n",
      "Minibatch 400 / loss: 0.676376\n",
      "Minibatch 400 / accuracy: 0.591797\n",
      "Minibatch 500 / loss: 0.642013\n",
      "Minibatch 500 / accuracy: 0.615234\n",
      "Minibatch 600 / loss: 0.64066\n",
      "Minibatch 600 / accuracy: 0.580078\n",
      "epoch time: 0.14918204148610434\n",
      "Epoch 7 training accuracy: 0.598915625\n",
      "Epoch 7 ... test ...\n",
      "Minibatch 100 / loss: 0.66295\n",
      "Minibatch 100 / accuracy: 0.59375\n",
      "Epoch 7 test accuracy: 0.5857125\n",
      "{'loss': 0.63896230468750004, 'valid_los': 0.64860654296874998, 'best_accuracy': 0.59891562499999995, 'best_test_accuracy': 0.59299999999999997, 'epoch': 6, 'learning_rate': 0.006666666666666667, 'valid_perplexity': 1.9128734640379075}\n",
      "Epoch 8 ... training ...\n",
      "Minibatch 100 / loss: 0.6625\n",
      "Minibatch 100 / accuracy: 0.560547\n",
      "Minibatch 200 / loss: 0.655109\n",
      "Minibatch 200 / accuracy: 0.574219\n",
      "Minibatch 300 / loss: 0.642004\n",
      "Minibatch 300 / accuracy: 0.609375\n",
      "Minibatch 400 / loss: 0.637099\n",
      "Minibatch 400 / accuracy: 0.621094\n",
      "Minibatch 500 / loss: 0.637774\n",
      "Minibatch 500 / accuracy: 0.597656\n",
      "Minibatch 600 / loss: 0.652568\n",
      "Minibatch 600 / accuracy: 0.591797\n",
      "epoch time: 0.1475691278775533\n",
      "Epoch 8 training accuracy: 0.60041875\n",
      "Epoch 8 ... test ...\n",
      "Minibatch 100 / loss: 0.654502\n",
      "Minibatch 100 / accuracy: 0.583984\n",
      "Epoch 8 test accuracy: 0.5860625\n",
      "{'loss': 0.63736367187499998, 'valid_los': 0.64866308593749999, 'best_accuracy': 0.60041875, 'best_test_accuracy': 0.59299999999999997, 'epoch': 7, 'learning_rate': 0.006666666666666667, 'valid_perplexity': 1.9129816266402957}\n",
      "Epoch 9 ... training ...\n",
      "Minibatch 100 / loss: 0.634568\n",
      "Minibatch 100 / accuracy: 0.576172\n",
      "Minibatch 200 / loss: 0.636948\n",
      "Minibatch 200 / accuracy: 0.578125\n",
      "Minibatch 300 / loss: 0.629743\n",
      "Minibatch 300 / accuracy: 0.599609\n",
      "Minibatch 400 / loss: 0.646435\n",
      "Minibatch 400 / accuracy: 0.566406\n",
      "Minibatch 500 / loss: 0.64536\n",
      "Minibatch 500 / accuracy: 0.615234\n",
      "Minibatch 600 / loss: 0.61949\n",
      "Minibatch 600 / accuracy: 0.628906\n",
      "epoch time: 0.148267928759257\n",
      "Epoch 9 training accuracy: 0.60291875\n",
      "Epoch 9 ... test ...\n",
      "Minibatch 100 / loss: 0.654361\n",
      "Minibatch 100 / accuracy: 0.587891\n",
      "Epoch 9 test accuracy: 0.5876625\n",
      "{'loss': 0.63378632812500002, 'valid_los': 0.64772841796875003, 'best_accuracy': 0.60291874999999995, 'best_test_accuracy': 0.59299999999999997, 'epoch': 8, 'learning_rate': 0.0044444444444444444, 'valid_perplexity': 1.9111944593231973}\n",
      "Epoch 10 ... training ...\n",
      "Minibatch 100 / loss: 0.60714\n",
      "Minibatch 100 / accuracy: 0.638672\n",
      "Minibatch 200 / loss: 0.630212\n",
      "Minibatch 200 / accuracy: 0.601562\n",
      "Minibatch 300 / loss: 0.625041\n",
      "Minibatch 300 / accuracy: 0.595703\n",
      "Minibatch 400 / loss: 0.628583\n",
      "Minibatch 400 / accuracy: 0.623047\n",
      "Minibatch 500 / loss: 0.615838\n",
      "Minibatch 500 / accuracy: 0.615234\n",
      "Minibatch 600 / loss: 0.606614\n",
      "Minibatch 600 / accuracy: 0.611328\n",
      "epoch time: 0.14974543650945027\n",
      "Epoch 10 training accuracy: 0.605259375\n",
      "Epoch 10 ... test ...\n",
      "Minibatch 100 / loss: 0.656491\n",
      "Minibatch 100 / accuracy: 0.587891\n",
      "Epoch 10 test accuracy: 0.59195\n",
      "{'loss': 0.632493603515625, 'valid_los': 0.64724228515625004, 'best_accuracy': 0.60525937500000004, 'best_test_accuracy': 0.59299999999999997, 'epoch': 9, 'learning_rate': 0.0044444444444444444, 'valid_perplexity': 1.9102655907804835}\n",
      "Epoch 11 ... training ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch 100 / loss: 0.621374\n",
      "Minibatch 100 / accuracy: 0.613281\n",
      "Minibatch 200 / loss: 0.645099\n",
      "Minibatch 200 / accuracy: 0.554688\n",
      "Minibatch 300 / loss: 0.636431\n",
      "Minibatch 300 / accuracy: 0.625\n",
      "Minibatch 400 / loss: 0.624296\n",
      "Minibatch 400 / accuracy: 0.582031\n",
      "Minibatch 500 / loss: 0.613126\n",
      "Minibatch 500 / accuracy: 0.617188\n",
      "Minibatch 600 / loss: 0.630065\n",
      "Minibatch 600 / accuracy: 0.640625\n",
      "epoch time: 0.14357958634694418\n",
      "Epoch 11 training accuracy: 0.6059875\n",
      "Epoch 11 ... test ...\n",
      "Minibatch 100 / loss: 0.666996\n",
      "Minibatch 100 / accuracy: 0.595703\n",
      "Epoch 11 test accuracy: 0.5920125\n",
      "{'loss': 0.63150625000000005, 'valid_los': 0.64811601562499999, 'best_accuracy': 0.60598750000000001, 'best_test_accuracy': 0.59299999999999997, 'epoch': 10, 'learning_rate': 0.0044444444444444444, 'valid_perplexity': 1.9119353773960472}\n",
      "Epoch 12 ... training ...\n",
      "Minibatch 100 / loss: 0.630906\n",
      "Minibatch 100 / accuracy: 0.605469\n",
      "Minibatch 200 / loss: 0.615307\n",
      "Minibatch 200 / accuracy: 0.619141\n",
      "Minibatch 300 / loss: 0.600922\n",
      "Minibatch 300 / accuracy: 0.652344\n",
      "Minibatch 400 / loss: 0.628159\n",
      "Minibatch 400 / accuracy: 0.589844\n",
      "Minibatch 500 / loss: 0.657025\n",
      "Minibatch 500 / accuracy: 0.574219\n",
      "Minibatch 600 / loss: 0.624871\n",
      "Minibatch 600 / accuracy: 0.615234\n",
      "epoch time: 0.15139222542444866\n",
      "Epoch 12 training accuracy: 0.607840625\n",
      "Epoch 12 ... test ...\n",
      "Minibatch 100 / loss: 0.659702\n",
      "Minibatch 100 / accuracy: 0.587891\n",
      "Epoch 12 test accuracy: 0.59245\n",
      "{'loss': 0.62891591796875002, 'valid_los': 0.64673388671874998, 'best_accuracy': 0.60784062500000002, 'best_test_accuracy': 0.59299999999999997, 'epoch': 11, 'learning_rate': 0.002962962962962963, 'valid_perplexity': 1.9092946615692805}\n",
      "Epoch 13 ... training ...\n",
      "Minibatch 100 / loss: 0.61824\n",
      "Minibatch 100 / accuracy: 0.605469\n",
      "Minibatch 200 / loss: 0.63089\n",
      "Minibatch 200 / accuracy: 0.642578\n",
      "Minibatch 300 / loss: 0.626605\n",
      "Minibatch 300 / accuracy: 0.646484\n",
      "Minibatch 400 / loss: 0.603223\n",
      "Minibatch 400 / accuracy: 0.634766\n",
      "Minibatch 500 / loss: 0.620508\n",
      "Minibatch 500 / accuracy: 0.625\n",
      "Minibatch 600 / loss: 0.633406\n",
      "Minibatch 600 / accuracy: 0.574219\n",
      "epoch time: 0.14672531684239706\n",
      "Epoch 13 training accuracy: 0.608690625\n",
      "Epoch 13 ... test ...\n",
      "Minibatch 100 / loss: 0.654409\n",
      "Minibatch 100 / accuracy: 0.583984\n",
      "Epoch 13 test accuracy: 0.5961\n",
      "Model saved in file: model/user_rank_model.ckpt\n",
      "{'loss': 0.62812133789062496, 'valid_los': 0.64576137695312497, 'best_accuracy': 0.60869062500000004, 'best_test_accuracy': 0.59609999999999996, 'epoch': 12, 'learning_rate': 0.002962962962962963, 'valid_perplexity': 1.9074387564546451}\n",
      "Epoch 14 ... training ...\n",
      "Minibatch 100 / loss: 0.63534\n",
      "Minibatch 100 / accuracy: 0.617188\n",
      "Minibatch 200 / loss: 0.643599\n",
      "Minibatch 200 / accuracy: 0.597656\n",
      "Minibatch 300 / loss: 0.621931\n",
      "Minibatch 300 / accuracy: 0.623047\n",
      "Minibatch 400 / loss: 0.627721\n",
      "Minibatch 400 / accuracy: 0.59375\n",
      "Minibatch 500 / loss: 0.627396\n",
      "Minibatch 500 / accuracy: 0.587891\n",
      "Minibatch 600 / loss: 0.604047\n",
      "Minibatch 600 / accuracy: 0.613281\n",
      "epoch time: 0.150255290667216\n",
      "Epoch 14 training accuracy: 0.60935\n",
      "Epoch 14 ... test ...\n",
      "Minibatch 100 / loss: 0.654604\n",
      "Minibatch 100 / accuracy: 0.591797\n",
      "Epoch 14 test accuracy: 0.598125\n",
      "Model saved in file: model/user_rank_model.ckpt\n",
      "{'loss': 0.62737363281250003, 'valid_los': 0.64606826171874998, 'best_accuracy': 0.60934999999999995, 'best_test_accuracy': 0.59812500000000002, 'epoch': 13, 'learning_rate': 0.002962962962962963, 'valid_perplexity': 1.9080242101791836}\n",
      "Epoch 15 ... training ...\n",
      "Minibatch 100 / loss: 0.612219\n",
      "Minibatch 100 / accuracy: 0.609375\n",
      "Minibatch 200 / loss: 0.633975\n",
      "Minibatch 200 / accuracy: 0.591797\n",
      "Minibatch 300 / loss: 0.627639\n",
      "Minibatch 300 / accuracy: 0.617188\n",
      "Minibatch 400 / loss: 0.642586\n",
      "Minibatch 400 / accuracy: 0.617188\n",
      "Minibatch 500 / loss: 0.626403\n",
      "Minibatch 500 / accuracy: 0.605469\n",
      "Minibatch 600 / loss: 0.659565\n",
      "Minibatch 600 / accuracy: 0.601562\n",
      "epoch time: 0.15082905292510987\n",
      "Epoch 15 training accuracy: 0.611625\n",
      "Epoch 15 ... test ...\n",
      "Minibatch 100 / loss: 0.652905\n",
      "Minibatch 100 / accuracy: 0.585938\n",
      "Epoch 15 test accuracy: 0.595925\n",
      "{'loss': 0.62572587890624998, 'valid_los': 0.64594418945312504, 'best_accuracy': 0.61162499999999997, 'best_test_accuracy': 0.59812500000000002, 'epoch': 14, 'learning_rate': 0.0019753086419753087, 'valid_perplexity': 1.9077874919779447}\n",
      "Epoch 16 ... training ...\n",
      "Minibatch 100 / loss: 0.626352\n",
      "Minibatch 100 / accuracy: 0.59375\n",
      "Minibatch 200 / loss: 0.635348\n",
      "Minibatch 200 / accuracy: 0.619141\n",
      "Minibatch 300 / loss: 0.624458\n",
      "Minibatch 300 / accuracy: 0.615234\n",
      "Minibatch 400 / loss: 0.635485\n",
      "Minibatch 400 / accuracy: 0.613281\n",
      "Minibatch 500 / loss: 0.637921\n",
      "Minibatch 500 / accuracy: 0.599609\n",
      "Minibatch 600 / loss: 0.619354\n",
      "Minibatch 600 / accuracy: 0.632812\n",
      "epoch time: 0.14675774176915488\n",
      "Epoch 16 training accuracy: 0.611421875\n",
      "Epoch 16 ... test ...\n",
      "Minibatch 100 / loss: 0.652707\n",
      "Minibatch 100 / accuracy: 0.587891\n",
      "Epoch 16 test accuracy: 0.5949125\n",
      "{'loss': 0.62501782226562497, 'valid_los': 0.64586132812499997, 'best_accuracy': 0.61162499999999997, 'best_test_accuracy': 0.59812500000000002, 'epoch': 15, 'learning_rate': 0.0019753086419753087, 'valid_perplexity': 1.9076294167218324}\n",
      "Epoch 17 ... training ...\n",
      "Minibatch 100 / loss: 0.630849\n",
      "Minibatch 100 / accuracy: 0.630859\n",
      "Minibatch 200 / loss: 0.620852\n",
      "Minibatch 200 / accuracy: 0.626953\n",
      "Minibatch 300 / loss: 0.621442\n",
      "Minibatch 300 / accuracy: 0.587891\n",
      "Minibatch 400 / loss: 0.620811\n",
      "Minibatch 400 / accuracy: 0.638672\n",
      "Minibatch 500 / loss: 0.646601\n",
      "Minibatch 500 / accuracy: 0.59375\n",
      "Minibatch 600 / loss: 0.608629\n",
      "Minibatch 600 / accuracy: 0.617188\n",
      "epoch time: 0.15002348025639853\n",
      "Epoch 17 training accuracy: 0.6120625\n",
      "Epoch 17 ... test ...\n",
      "Minibatch 100 / loss: 0.65243\n",
      "Minibatch 100 / accuracy: 0.585938\n",
      "Epoch 17 test accuracy: 0.589525\n",
      "{'loss': 0.62455800781250004, 'valid_los': 0.64624804687500004, 'best_accuracy': 0.61206249999999995, 'best_test_accuracy': 0.59812500000000002, 'epoch': 16, 'learning_rate': 0.0019753086419753087, 'valid_perplexity': 1.908367275448037}\n",
      "Epoch 18 ... training ...\n",
      "Minibatch 100 / loss: 0.635253\n",
      "Minibatch 100 / accuracy: 0.650391\n",
      "Minibatch 200 / loss: 0.629997\n",
      "Minibatch 200 / accuracy: 0.599609\n",
      "Minibatch 300 / loss: 0.611823\n",
      "Minibatch 300 / accuracy: 0.644531\n",
      "Minibatch 400 / loss: 0.607777\n",
      "Minibatch 400 / accuracy: 0.619141\n",
      "Minibatch 500 / loss: 0.610874\n",
      "Minibatch 500 / accuracy: 0.619141\n",
      "Minibatch 600 / loss: 0.632882\n",
      "Minibatch 600 / accuracy: 0.589844\n",
      "epoch time: 0.14519209861755372\n",
      "Epoch 18 training accuracy: 0.612690625\n",
      "Epoch 18 ... test ...\n",
      "Minibatch 100 / loss: 0.656587\n",
      "Minibatch 100 / accuracy: 0.585938\n",
      "Epoch 18 test accuracy: 0.596825\n",
      "{'loss': 0.62329912109374996, 'valid_los': 0.64645483398437498, 'best_accuracy': 0.61269062500000004, 'best_test_accuracy': 0.59812500000000002, 'epoch': 17, 'learning_rate': 0.0013168724279835392, 'valid_perplexity': 1.9087619420051245}\n",
      "Epoch 19 ... training ...\n",
      "Minibatch 100 / loss: 0.605118\n",
      "Minibatch 100 / accuracy: 0.630859\n",
      "Minibatch 200 / loss: 0.622964\n",
      "Minibatch 200 / accuracy: 0.646484\n",
      "Minibatch 300 / loss: 0.609892\n",
      "Minibatch 300 / accuracy: 0.630859\n",
      "Minibatch 400 / loss: 0.615572\n",
      "Minibatch 400 / accuracy: 0.638672\n",
      "Minibatch 500 / loss: 0.612522\n",
      "Minibatch 500 / accuracy: 0.609375\n",
      "Minibatch 600 / loss: 0.619859\n",
      "Minibatch 600 / accuracy: 0.619141\n",
      "epoch time: 0.15153319040934246\n",
      "Epoch 19 training accuracy: 0.61459375\n",
      "Epoch 19 ... test ...\n",
      "Minibatch 100 / loss: 0.65454\n",
      "Minibatch 100 / accuracy: 0.585938\n",
      "Epoch 19 test accuracy: 0.5915\n",
      "{'loss': 0.62240327148437502, 'valid_los': 0.64562451171875002, 'best_accuracy': 0.61459375000000005, 'best_test_accuracy': 0.59812500000000002, 'epoch': 18, 'learning_rate': 0.0008779149519890262, 'valid_perplexity': 1.9071777122665317}\n",
      "Epoch 20 ... training ...\n",
      "Minibatch 100 / loss: 0.616378\n",
      "Minibatch 100 / accuracy: 0.619141\n",
      "Minibatch 200 / loss: 0.622758\n",
      "Minibatch 200 / accuracy: 0.59375\n",
      "Minibatch 300 / loss: 0.621394\n",
      "Minibatch 300 / accuracy: 0.597656\n",
      "Minibatch 400 / loss: 0.626754\n",
      "Minibatch 400 / accuracy: 0.642578\n",
      "Minibatch 500 / loss: 0.616778\n",
      "Minibatch 500 / accuracy: 0.640625\n",
      "Minibatch 600 / loss: 0.605762\n",
      "Minibatch 600 / accuracy: 0.650391\n",
      "epoch time: 0.1491860349973043\n",
      "Epoch 20 training accuracy: 0.614484375\n",
      "Epoch 20 ... test ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch 100 / loss: 0.653642\n",
      "Minibatch 100 / accuracy: 0.585938\n",
      "Epoch 20 test accuracy: 0.594725\n",
      "{'loss': 0.62211362304687501, 'valid_los': 0.64579150390624995, 'best_accuracy': 0.61459375000000005, 'best_test_accuracy': 0.59812500000000002, 'epoch': 19, 'learning_rate': 0.0008779149519890262, 'valid_perplexity': 1.9074962226382859}\n",
      "Epoch 21 ... training ...\n",
      "Minibatch 100 / loss: 0.615822\n",
      "Minibatch 100 / accuracy: 0.671875\n",
      "Minibatch 200 / loss: 0.62228\n",
      "Minibatch 200 / accuracy: 0.650391\n",
      "Minibatch 300 / loss: 0.608403\n",
      "Minibatch 300 / accuracy: 0.619141\n",
      "Minibatch 400 / loss: 0.631071\n",
      "Minibatch 400 / accuracy: 0.587891\n",
      "Minibatch 500 / loss: 0.604984\n",
      "Minibatch 500 / accuracy: 0.646484\n",
      "Minibatch 600 / loss: 0.603402\n",
      "Minibatch 600 / accuracy: 0.619141\n",
      "epoch time: 0.14755463202794392\n",
      "Epoch 21 training accuracy: 0.614565625\n",
      "Epoch 21 ... test ...\n",
      "Minibatch 100 / loss: 0.654825\n",
      "Minibatch 100 / accuracy: 0.585938\n",
      "Epoch 21 test accuracy: 0.5959\n",
      "{'loss': 0.62156611328125, 'valid_los': 0.64570234375000002, 'best_accuracy': 0.61459375000000005, 'best_test_accuracy': 0.59812500000000002, 'epoch': 20, 'learning_rate': 0.0005852766346593508, 'valid_perplexity': 1.9073261575586564}\n",
      "Epoch 22 ... training ...\n",
      "Minibatch 100 / loss: 0.604169\n",
      "Minibatch 100 / accuracy: 0.617188\n",
      "Minibatch 200 / loss: 0.622497\n",
      "Minibatch 200 / accuracy: 0.623047\n",
      "Minibatch 300 / loss: 0.626592\n",
      "Minibatch 300 / accuracy: 0.621094\n",
      "Minibatch 400 / loss: 0.641269\n",
      "Minibatch 400 / accuracy: 0.619141\n",
      "Minibatch 500 / loss: 0.649707\n",
      "Minibatch 500 / accuracy: 0.589844\n",
      "Minibatch 600 / loss: 0.62227\n",
      "Minibatch 600 / accuracy: 0.603516\n",
      "epoch time: 0.14208358526229858\n",
      "Epoch 22 training accuracy: 0.614390625\n",
      "Epoch 22 ... test ...\n",
      "Minibatch 100 / loss: 0.653289\n",
      "Minibatch 100 / accuracy: 0.587891\n",
      "Epoch 22 test accuracy: 0.5935\n",
      "{'loss': 0.62139082031250004, 'valid_los': 0.64552441406250005, 'best_accuracy': 0.61459375000000005, 'best_test_accuracy': 0.59812500000000002, 'epoch': 21, 'learning_rate': 0.0005852766346593508, 'valid_perplexity': 1.906986817801685}\n",
      "Epoch 23 ... training ...\n",
      "Minibatch 100 / loss: 0.604128\n",
      "Minibatch 100 / accuracy: 0.642578\n",
      "Minibatch 200 / loss: 0.624613\n",
      "Minibatch 200 / accuracy: 0.582031\n",
      "Minibatch 300 / loss: 0.634784\n",
      "Minibatch 300 / accuracy: 0.601562\n",
      "Minibatch 400 / loss: 0.624546\n",
      "Minibatch 400 / accuracy: 0.615234\n",
      "Minibatch 500 / loss: 0.62397\n",
      "Minibatch 500 / accuracy: 0.601562\n",
      "Minibatch 600 / loss: 0.64932\n",
      "Minibatch 600 / accuracy: 0.580078\n",
      "epoch time: 0.14721893866856892\n",
      "Epoch 23 training accuracy: 0.61523125\n",
      "Epoch 23 ... test ...\n",
      "Minibatch 100 / loss: 0.65238\n",
      "Minibatch 100 / accuracy: 0.585938\n",
      "Epoch 23 test accuracy: 0.5937625\n",
      "{'loss': 0.62116518554687505, 'valid_los': 0.64564248046874995, 'best_accuracy': 0.61523125000000001, 'best_test_accuracy': 0.59812500000000002, 'epoch': 22, 'learning_rate': 0.0005852766346593508, 'valid_perplexity': 1.9072119821739415}\n",
      "Epoch 24 ... training ...\n",
      "Minibatch 100 / loss: 0.606059\n",
      "Minibatch 100 / accuracy: 0.636719\n",
      "Minibatch 200 / loss: 0.62705\n",
      "Minibatch 200 / accuracy: 0.609375\n",
      "Minibatch 300 / loss: 0.609619\n",
      "Minibatch 300 / accuracy: 0.640625\n",
      "Minibatch 400 / loss: 0.617361\n",
      "Minibatch 400 / accuracy: 0.625\n",
      "Minibatch 500 / loss: 0.623607\n",
      "Minibatch 500 / accuracy: 0.607422\n",
      "Minibatch 600 / loss: 0.625817\n",
      "Minibatch 600 / accuracy: 0.578125\n",
      "epoch time: 0.14865785439809162\n",
      "Epoch 24 training accuracy: 0.616071875\n",
      "Epoch 24 ... test ...\n",
      "Minibatch 100 / loss: 0.653242\n",
      "Minibatch 100 / accuracy: 0.585938\n",
      "Epoch 24 test accuracy: 0.595525\n",
      "{'loss': 0.62079687500000003, 'valid_los': 0.64562382812499997, 'best_accuracy': 0.61607187500000005, 'best_test_accuracy': 0.59812500000000002, 'epoch': 23, 'learning_rate': 0.0003901844231062339, 'valid_perplexity': 1.907176408532213}\n",
      "Epoch 25 ... training ...\n",
      "Minibatch 100 / loss: 0.61477\n",
      "Minibatch 100 / accuracy: 0.638672\n",
      "Minibatch 200 / loss: 0.628043\n",
      "Minibatch 200 / accuracy: 0.560547\n",
      "Minibatch 300 / loss: 0.602849\n",
      "Minibatch 300 / accuracy: 0.617188\n",
      "Minibatch 400 / loss: 0.611847\n",
      "Minibatch 400 / accuracy: 0.628906\n",
      "Minibatch 500 / loss: 0.634297\n",
      "Minibatch 500 / accuracy: 0.591797\n",
      "Minibatch 600 / loss: 0.627219\n",
      "Minibatch 600 / accuracy: 0.613281\n",
      "epoch time: 0.14783907334009808\n",
      "Epoch 25 training accuracy: 0.6157875\n",
      "Epoch 25 ... test ...\n",
      "Minibatch 100 / loss: 0.653516\n",
      "Minibatch 100 / accuracy: 0.585938\n",
      "Epoch 25 test accuracy: 0.595225\n",
      "{'loss': 0.62049243164062495, 'valid_los': 0.64554291992187496, 'best_accuracy': 0.61607187500000005, 'best_test_accuracy': 0.59812500000000002, 'epoch': 24, 'learning_rate': 0.00026012294873748923, 'valid_perplexity': 1.9070221085581072}\n",
      "Epoch 26 ... training ...\n",
      "Minibatch 100 / loss: 0.619299\n",
      "Minibatch 100 / accuracy: 0.630859\n",
      "Minibatch 200 / loss: 0.649623\n",
      "Minibatch 200 / accuracy: 0.566406\n",
      "Minibatch 300 / loss: 0.601302\n",
      "Minibatch 300 / accuracy: 0.648438\n",
      "Minibatch 400 / loss: 0.624903\n",
      "Minibatch 400 / accuracy: 0.621094\n",
      "Minibatch 500 / loss: 0.617043\n",
      "Minibatch 500 / accuracy: 0.630859\n",
      "Minibatch 600 / loss: 0.639423\n",
      "Minibatch 600 / accuracy: 0.572266\n",
      "epoch time: 0.15047003428141276\n",
      "Epoch 26 training accuracy: 0.6160625\n",
      "Epoch 26 ... test ...\n",
      "Minibatch 100 / loss: 0.653079\n",
      "Minibatch 100 / accuracy: 0.585938\n",
      "Epoch 26 test accuracy: 0.594675\n",
      "{'loss': 0.620431201171875, 'valid_los': 0.64551376953124995, 'best_accuracy': 0.61607187500000005, 'best_test_accuracy': 0.59812500000000002, 'epoch': 25, 'learning_rate': 0.00026012294873748923, 'valid_perplexity': 1.9069665189289458}\n",
      "Epoch 27 ... training ...\n",
      "Minibatch 100 / loss: 0.606825\n",
      "Minibatch 100 / accuracy: 0.601562\n",
      "Minibatch 200 / loss: 0.617717\n",
      "Minibatch 200 / accuracy: 0.625\n",
      "Minibatch 300 / loss: 0.610354\n",
      "Minibatch 300 / accuracy: 0.603516\n",
      "Minibatch 400 / loss: 0.62279\n",
      "Minibatch 400 / accuracy: 0.595703\n",
      "Minibatch 500 / loss: 0.628504\n",
      "Minibatch 500 / accuracy: 0.609375\n",
      "Minibatch 600 / loss: 0.633495\n",
      "Minibatch 600 / accuracy: 0.617188\n",
      "epoch time: 0.15059901475906373\n",
      "Epoch 27 training accuracy: 0.616528125\n",
      "Epoch 27 ... test ...\n",
      "Minibatch 100 / loss: 0.652738\n",
      "Minibatch 100 / accuracy: 0.585938\n",
      "Epoch 27 test accuracy: 0.593025\n",
      "{'loss': 0.6202140625, 'valid_los': 0.64554521484375005, 'best_accuracy': 0.61652812499999998, 'best_test_accuracy': 0.59812500000000002, 'epoch': 26, 'learning_rate': 0.00017341529915832616, 'valid_perplexity': 1.9070264850298821}\n",
      "Epoch 28 ... training ...\n",
      "Minibatch 100 / loss: 0.622095\n",
      "Minibatch 100 / accuracy: 0.615234\n",
      "Minibatch 200 / loss: 0.619844\n",
      "Minibatch 200 / accuracy: 0.611328\n",
      "Minibatch 300 / loss: 0.603747\n",
      "Minibatch 300 / accuracy: 0.619141\n",
      "Minibatch 400 / loss: 0.627817\n",
      "Minibatch 400 / accuracy: 0.572266\n",
      "Minibatch 500 / loss: 0.627871\n",
      "Minibatch 500 / accuracy: 0.603516\n",
      "Minibatch 600 / loss: 0.61138\n",
      "Minibatch 600 / accuracy: 0.632812\n",
      "epoch time: 0.14857516686121622\n",
      "Epoch 28 training accuracy: 0.616240625\n",
      "Epoch 28 ... test ...\n",
      "Minibatch 100 / loss: 0.652779\n",
      "Minibatch 100 / accuracy: 0.585938\n",
      "Epoch 28 test accuracy: 0.5950375\n",
      "{'loss': 0.6200919921875, 'valid_los': 0.64549833984375005, 'best_accuracy': 0.61652812499999998, 'best_test_accuracy': 0.59812500000000002, 'epoch': 27, 'learning_rate': 0.00011561019943888411, 'valid_perplexity': 1.9069370952584854}\n",
      "Epoch 29 ... training ...\n",
      "Minibatch 100 / loss: 0.647449\n",
      "Minibatch 100 / accuracy: 0.603516\n",
      "Minibatch 200 / loss: 0.615392\n",
      "Minibatch 200 / accuracy: 0.634766\n",
      "Minibatch 300 / loss: 0.611746\n",
      "Minibatch 300 / accuracy: 0.613281\n",
      "Minibatch 400 / loss: 0.629967\n",
      "Minibatch 400 / accuracy: 0.609375\n",
      "Minibatch 500 / loss: 0.620306\n",
      "Minibatch 500 / accuracy: 0.59375\n",
      "Minibatch 600 / loss: 0.5976\n",
      "Minibatch 600 / accuracy: 0.646484\n",
      "epoch time: 0.15115024248758951\n",
      "Epoch 29 training accuracy: 0.616625\n",
      "Epoch 29 ... test ...\n",
      "Minibatch 100 / loss: 0.652737\n",
      "Minibatch 100 / accuracy: 0.585938\n",
      "Epoch 29 test accuracy: 0.5942875\n",
      "{'loss': 0.61998852539062499, 'valid_los': 0.64554018554687498, 'best_accuracy': 0.61662499999999998, 'best_test_accuracy': 0.59812500000000002, 'epoch': 28, 'learning_rate': 7.70734662925894e-05, 'valid_perplexity': 1.9070168940516583}\n",
      "Epoch 30 ... training ...\n",
      "Minibatch 100 / loss: 0.616114\n",
      "Minibatch 100 / accuracy: 0.607422\n",
      "Minibatch 200 / loss: 0.630779\n",
      "Minibatch 200 / accuracy: 0.589844\n",
      "Minibatch 300 / loss: 0.644017\n",
      "Minibatch 300 / accuracy: 0.613281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch 400 / loss: 0.639771\n",
      "Minibatch 400 / accuracy: 0.619141\n",
      "Minibatch 500 / loss: 0.630145\n",
      "Minibatch 500 / accuracy: 0.611328\n",
      "Minibatch 600 / loss: 0.627321\n",
      "Minibatch 600 / accuracy: 0.603516\n",
      "epoch time: 0.14614883263905842\n",
      "Epoch 30 training accuracy: 0.616565625\n",
      "Epoch 30 ... test ...\n",
      "Minibatch 100 / loss: 0.652786\n",
      "Minibatch 100 / accuracy: 0.585938\n",
      "Epoch 30 test accuracy: 0.5942875\n",
      "{'loss': 0.61993437500000004, 'valid_los': 0.64553510742187503, 'best_accuracy': 0.61662499999999998, 'best_test_accuracy': 0.59812500000000002, 'epoch': 29, 'learning_rate': 5.138231086172627e-05, 'valid_perplexity': 1.9070072100060818}\n",
      "Epoch 31 ... training ...\n",
      "Minibatch 100 / loss: 0.610137\n",
      "Minibatch 100 / accuracy: 0.654297\n",
      "Minibatch 200 / loss: 0.631576\n",
      "Minibatch 200 / accuracy: 0.603516\n",
      "Minibatch 300 / loss: 0.654688\n",
      "Minibatch 300 / accuracy: 0.570312\n",
      "Minibatch 400 / loss: 0.604622\n",
      "Minibatch 400 / accuracy: 0.617188\n",
      "Minibatch 500 / loss: 0.633797\n",
      "Minibatch 500 / accuracy: 0.601562\n",
      "Minibatch 600 / loss: 0.635757\n",
      "Minibatch 600 / accuracy: 0.585938\n",
      "epoch time: 0.15055836836496989\n",
      "Epoch 31 training accuracy: 0.61646875\n",
      "Epoch 31 ... test ...\n",
      "Minibatch 100 / loss: 0.652862\n",
      "Minibatch 100 / accuracy: 0.585938\n",
      "Epoch 31 test accuracy: 0.594175\n",
      "{'loss': 0.61988916015624995, 'valid_los': 0.64552026367187498, 'best_accuracy': 0.61662499999999998, 'best_test_accuracy': 0.59812500000000002, 'epoch': 30, 'learning_rate': 3.425487390781751e-05, 'valid_perplexity': 1.906978903077899}\n",
      "Epoch 32 ... training ...\n",
      "Minibatch 100 / loss: 0.608452\n",
      "Minibatch 100 / accuracy: 0.589844\n",
      "Minibatch 200 / loss: 0.613826\n",
      "Minibatch 200 / accuracy: 0.623047\n",
      "Minibatch 300 / loss: 0.610164\n",
      "Minibatch 300 / accuracy: 0.650391\n",
      "Minibatch 400 / loss: 0.626824\n",
      "Minibatch 400 / accuracy: 0.613281\n",
      "Minibatch 500 / loss: 0.644397\n",
      "Minibatch 500 / accuracy: 0.558594\n",
      "Minibatch 600 / loss: 0.633539\n",
      "Minibatch 600 / accuracy: 0.619141\n",
      "epoch time: 0.14816335439682007\n",
      "Epoch 32 training accuracy: 0.61655625\n",
      "Epoch 32 ... test ...\n",
      "Minibatch 100 / loss: 0.652792\n",
      "Minibatch 100 / accuracy: 0.585938\n",
      "Epoch 32 test accuracy: 0.5941\n",
      "{'loss': 0.61985595703124996, 'valid_los': 0.64552753906250004, 'best_accuracy': 0.61662499999999998, 'best_test_accuracy': 0.59812500000000002, 'epoch': 31, 'learning_rate': 2.2836582605211673e-05, 'valid_perplexity': 1.9069927771448023}\n",
      "Epoch 33 ... training ...\n",
      "Minibatch 100 / loss: 0.609873\n",
      "Minibatch 100 / accuracy: 0.634766\n",
      "Minibatch 200 / loss: 0.633646\n",
      "Minibatch 200 / accuracy: 0.632812\n",
      "Minibatch 300 / loss: 0.634561\n",
      "Minibatch 300 / accuracy: 0.605469\n",
      "Minibatch 400 / loss: 0.605451\n",
      "Minibatch 400 / accuracy: 0.626953\n",
      "Minibatch 500 / loss: 0.624413\n",
      "Minibatch 500 / accuracy: 0.603516\n",
      "Minibatch 600 / loss: 0.629295\n",
      "Minibatch 600 / accuracy: 0.615234\n",
      "epoch time: 0.15109822352727253\n",
      "Epoch 33 training accuracy: 0.61655625\n",
      "Epoch 33 ... test ...\n",
      "Minibatch 100 / loss: 0.652831\n",
      "Minibatch 100 / accuracy: 0.585938\n",
      "Epoch 33 test accuracy: 0.5942125\n",
      "{'loss': 0.61983823242187497, 'valid_los': 0.64553642578125003, 'best_accuracy': 0.61662499999999998, 'best_test_accuracy': 0.59812500000000002, 'epoch': 32, 'learning_rate': 1.522438840347445e-05, 'valid_perplexity': 1.9070097241285724}\n",
      "Epoch 34 ... training ...\n",
      "Minibatch 100 / loss: 0.605154\n",
      "Minibatch 100 / accuracy: 0.628906\n",
      "Minibatch 200 / loss: 0.618157\n",
      "Minibatch 200 / accuracy: 0.615234\n",
      "Minibatch 300 / loss: 0.630946\n",
      "Minibatch 300 / accuracy: 0.597656\n",
      "Minibatch 400 / loss: 0.638883\n",
      "Minibatch 400 / accuracy: 0.59375\n",
      "Minibatch 500 / loss: 0.625557\n",
      "Minibatch 500 / accuracy: 0.587891\n",
      "Minibatch 600 / loss: 0.627323\n",
      "Minibatch 600 / accuracy: 0.601562\n",
      "epoch time: 0.15061997572580973\n",
      "Epoch 34 training accuracy: 0.6164125\n",
      "Epoch 34 ... test ...\n",
      "Minibatch 100 / loss: 0.652859\n",
      "Minibatch 100 / accuracy: 0.585938\n",
      "Epoch 34 test accuracy: 0.5944\n",
      "{'loss': 0.61982519531250002, 'valid_los': 0.64553164062500001, 'best_accuracy': 0.61662499999999998, 'best_test_accuracy': 0.59812500000000002, 'epoch': 33, 'learning_rate': 1.0149592268982966e-05, 'valid_perplexity': 1.9070005988109053}\n"
     ]
    }
   ],
   "source": [
    "graph_to_use = tf.Graph()\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth=True\n",
    "with tf.Session(graph=graph_to_use, config=config) as session:\n",
    "    #cnn_model = TextCNN(FLAGS, session, current_task_name='text_cnn_model')\n",
    "    #cnn_model.build_model(num_classes=len(set(label[idxs])),max_conv_len=7, num_filters=512, dropout_keep_prob=0.5)\n",
    "    user_rank_model = UserRankModel(FLAGS, session, current_task_name='user_rank_model')\n",
    "    #label[idxs]\n",
    "    user_rank_model.build_model(net_size=512)\n",
    "    user_rank_model.build_model_summary()\n",
    "    display(user_rank_model.model_summary())\n",
    "    user_rank_model.run([data,event,label], train_idxs, test_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
